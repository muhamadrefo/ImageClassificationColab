{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM6 v2.5.b.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXPpwAgR08zaQUOZbRN7Nf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhamadrefo/ImageClassificationColab/blob/master/SVM6_v2_5_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leMI2hrB73Zg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ac7181e-41cd-49f3-a1f2-a73d1d493c68"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CG6uIlf_dtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f8ecf975-cc4d-4852-a91d-f21290f3b55c"
      },
      "source": [
        "#Importing Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split as tt, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "%matplotlib inline\n",
        "\n",
        "%cd /content/drive/My Drive/Batik/SVM/\n",
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Batik/SVM\n",
            "\u001b[0m\u001b[01;34mBatikYogya\u001b[0m/              LinearReport.csv       RsLinear3.csv\n",
            "DataGaussian.csv         nama_file.csv          RsLinear.csv\n",
            "DataTraining.csv         newDataTraining.csv    RsPolynomial.csv\n",
            "DataValidation.csv       newDataValidation.csv  RsSigmoid.csv\n",
            "GaussianReport_50_1.csv  PolyReport_50_1.csv    RsTryLinear2.csv\n",
            "GaussianReport_50_2.csv  PolyReport_50_2.csv    SigmoidReport_50_1.csv\n",
            "GaussianReport_50_3.csv  PolyReport_50_3.csv    SigmoidReport_50_2.csv\n",
            "LinearReport_50_1.csv    PrecisionTryLin.csv    SigmoidReport_50_3.csv\n",
            "LinearReport_50_2.csv    RsGauss.csv\n",
            "LinearReport_50_3.csv    RsLinear2.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctavhWPP_pWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dTrain = pd.read_csv('newDataTraining.csv')\n",
        "dValid = pd.read_csv('newDataTraining.csv')\n",
        "x = dTrain.iloc[:, 1:6].values\n",
        "y = dTrain.iloc[:, 7].values\n",
        "valDat = dValid.iloc[:, 1:6].values\n",
        "valTarget = dValid.iloc[:, 7].values\n",
        "iteration = 3\n",
        "epochs = 50\n",
        "\n",
        "def pandas_classification_report(y_true, y_pred):\n",
        "        metrics_summary = precision_recall_fscore_support(\n",
        "                y_true=y_true, \n",
        "                y_pred=y_pred)\n",
        "\n",
        "        avg = list(precision_recall_fscore_support(\n",
        "                y_true=y_true, \n",
        "                y_pred=y_pred,\n",
        "                average='weighted'))\n",
        "\n",
        "        metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
        "\n",
        "        class_report_df = pd.DataFrame(list(metrics_summary),index=metrics_sum_index)\n",
        "        support = class_report_df.loc['support']\n",
        "        total = support.sum() \n",
        "        avg[-1] = total\n",
        "        \n",
        "        # class_report_df = pd.DataFrame(index=metrics_sum_index)\n",
        "        class_report_df['avg / total'] = avg\n",
        "\n",
        "        return class_report_df.T\n",
        "\n",
        "def linear():\n",
        "  for itr in range(int(iteration)):\n",
        "    print('\\nIteration ', str(itr+1), ':\\n')\n",
        "    for epoch in range(int(epochs)):\n",
        "      model = SVC(kernel='linear')\n",
        "      x_train, x_test, y_train, y_test = tt(x,y, test_size=0.2, random_state=44)\n",
        "      model.fit(x_train, y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      accT = (np.sum(y_pred == y_test)/ y_test.size)*100\n",
        "      print('Accuracy Training  '+str(epoch+1)+': ', str(accT))\n",
        "    valPred = model.predict(valDat)\n",
        "    accV = (np.sum(valPred == valTarget)/ valTarget.size)*100\n",
        "    class_report = pandas_classification_report(valTarget, valPred)\n",
        "    print('Accuracy Validation  : ', str(accV))\n",
        "    print('Class Report         : \\n', str(class_report)) #0 as Cap, 1 as Tulis\n",
        "    class_report.to_csv('LinearReport'+'_'+str(epoch+1)+'_'+str(itr+1)+'.csv', mode='a', sep=';', encoding='utf-8', header=True)\n",
        "\n",
        "def poly():\n",
        "  for itr in range(int(iteration)):\n",
        "    print('\\nIteration ', str(itr+1), ':\\n')\n",
        "    for epoch in range(int(epochs)):\n",
        "      model = SVC(kernel='poly')\n",
        "      x_train, x_test, y_train, y_test = tt(x,y, test_size=0.2, random_state=44)\n",
        "      model.fit(x_train, y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      accT = (np.sum(y_pred == y_test)/ y_test.size)*100\n",
        "      print('Accuracy Training  '+str(epoch+1)+': ', str(accT))\n",
        "    valPred = model.predict(valDat)\n",
        "    accV = (np.sum(valPred == valTarget)/ valTarget.size)*100\n",
        "    class_report = pandas_classification_report(valTarget, valPred)\n",
        "    print('Accuracy Validation  : ', str(accV))\n",
        "    print('Class Report         : \\n', str(class_report)) #0 as Cap, 1 as Tulis\n",
        "    class_report.to_csv('PolyReport'+'_'+str(epoch+1)+'_'+str(itr+1)+'.csv', mode='a', sep=';', encoding='utf-8', header=True)\n",
        "\n",
        "\n",
        "def gaussian():\n",
        "  for itr in range(int(iteration)):\n",
        "    print('\\nIteration ', str(itr+1), ':\\n')\n",
        "    for epoch in range(int(epochs)):\n",
        "      model = SVC(kernel='rbf')\n",
        "      x_train, x_test, y_train, y_test = tt(x,y, test_size=0.2, random_state=44)\n",
        "      model.fit(x_train, y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      accT = (np.sum(y_pred == y_test)/ y_test.size)*100\n",
        "      print('Accuracy Training  '+str(epoch+1)+': ', str(accT))\n",
        "    valPred = model.predict(valDat)\n",
        "    accV = (np.sum(valPred == valTarget)/ valTarget.size)*100\n",
        "    class_report = pandas_classification_report(valTarget, valPred)\n",
        "    print('Accuracy Validation  : ', str(accV))\n",
        "    print('Class Report         : \\n', str(class_report)) #0 as Cap, 1 as Tulis\n",
        "    class_report.to_csv('GaussianReport'+'_'+str(epoch+1)+'_'+str(itr+1)+'.csv', mode='a', sep=';', encoding='utf-8', header=True)\n",
        "\n",
        "\n",
        "def sigmoid():\n",
        "  for itr in range(int(iteration)):\n",
        "    print('\\nIteration ', str(itr+1), ':\\n')\n",
        "    for epoch in range(int(epochs)):\n",
        "      model = SVC(kernel='sigmoid')\n",
        "      x_train, x_test, y_train, y_test = tt(x,y, test_size=0.2, random_state=44)\n",
        "      model.fit(x_train, y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      accT = (np.sum(y_pred == y_test)/ y_test.size)*100\n",
        "      print('Accuracy Training  '+str(epoch+1)+': ', str(accT))\n",
        "    valPred = model.predict(valDat)\n",
        "    accV = (np.sum(valPred == valTarget)/ valTarget.size)*100\n",
        "    class_report = pandas_classification_report(valTarget, valPred)\n",
        "    print('Accuracy Validation  : ', str(accV))\n",
        "    print('Class Report         : \\n', str(class_report)) #0 as Cap, 1 as Tulis\n",
        "    class_report.to_csv('SigmoidReport'+'_'+str(epoch+1)+'_'+str(itr+1)+'.csv', mode='a', sep=';', encoding='utf-8', header=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzGf8EUVALYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c09d144-0f4f-4d4c-dd61-f6fd05679d61"
      },
      "source": [
        "linear()\n",
        "show = pd.read_csv('LinearReport_50_2.csv')\n",
        "show"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  1 :\n",
            "\n",
            "Accuracy Training  1:  59.25925925925925\n",
            "Accuracy Training  2:  59.25925925925925\n",
            "Accuracy Training  3:  59.25925925925925\n",
            "Accuracy Training  4:  59.25925925925925\n",
            "Accuracy Training  5:  59.25925925925925\n",
            "Accuracy Training  6:  59.25925925925925\n",
            "Accuracy Training  7:  59.25925925925925\n",
            "Accuracy Training  8:  59.25925925925925\n",
            "Accuracy Training  9:  59.25925925925925\n",
            "Accuracy Training  10:  59.25925925925925\n",
            "Accuracy Training  11:  59.25925925925925\n",
            "Accuracy Training  12:  59.25925925925925\n",
            "Accuracy Training  13:  59.25925925925925\n",
            "Accuracy Training  14:  59.25925925925925\n",
            "Accuracy Training  15:  59.25925925925925\n",
            "Accuracy Training  16:  59.25925925925925\n",
            "Accuracy Training  17:  59.25925925925925\n",
            "Accuracy Training  18:  59.25925925925925\n",
            "Accuracy Training  19:  59.25925925925925\n",
            "Accuracy Training  20:  59.25925925925925\n",
            "Accuracy Training  21:  59.25925925925925\n",
            "Accuracy Training  22:  59.25925925925925\n",
            "Accuracy Training  23:  59.25925925925925\n",
            "Accuracy Training  24:  59.25925925925925\n",
            "Accuracy Training  25:  59.25925925925925\n",
            "Accuracy Training  26:  59.25925925925925\n",
            "Accuracy Training  27:  59.25925925925925\n",
            "Accuracy Training  28:  59.25925925925925\n",
            "Accuracy Training  29:  59.25925925925925\n",
            "Accuracy Training  30:  59.25925925925925\n",
            "Accuracy Training  31:  59.25925925925925\n",
            "Accuracy Training  32:  59.25925925925925\n",
            "Accuracy Training  33:  59.25925925925925\n",
            "Accuracy Training  34:  59.25925925925925\n",
            "Accuracy Training  35:  59.25925925925925\n",
            "Accuracy Training  36:  59.25925925925925\n",
            "Accuracy Training  37:  59.25925925925925\n",
            "Accuracy Training  38:  59.25925925925925\n",
            "Accuracy Training  39:  59.25925925925925\n",
            "Accuracy Training  40:  59.25925925925925\n",
            "Accuracy Training  41:  59.25925925925925\n",
            "Accuracy Training  42:  59.25925925925925\n",
            "Accuracy Training  43:  59.25925925925925\n",
            "Accuracy Training  44:  59.25925925925925\n",
            "Accuracy Training  45:  59.25925925925925\n",
            "Accuracy Training  46:  59.25925925925925\n",
            "Accuracy Training  47:  59.25925925925925\n",
            "Accuracy Training  48:  59.25925925925925\n",
            "Accuracy Training  49:  59.25925925925925\n",
            "Accuracy Training  50:  59.25925925925925\n",
            "Accuracy Validation  :  61.56716417910447\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.706897  0.442446  0.544248    278.0\n",
            "1             0.571823  0.802326  0.667742    258.0\n",
            "avg / total   0.641880  0.615672  0.603691    536.0\n",
            "\n",
            "Iteration  2 :\n",
            "\n",
            "Accuracy Training  1:  59.25925925925925\n",
            "Accuracy Training  2:  59.25925925925925\n",
            "Accuracy Training  3:  59.25925925925925\n",
            "Accuracy Training  4:  59.25925925925925\n",
            "Accuracy Training  5:  59.25925925925925\n",
            "Accuracy Training  6:  59.25925925925925\n",
            "Accuracy Training  7:  59.25925925925925\n",
            "Accuracy Training  8:  59.25925925925925\n",
            "Accuracy Training  9:  59.25925925925925\n",
            "Accuracy Training  10:  59.25925925925925\n",
            "Accuracy Training  11:  59.25925925925925\n",
            "Accuracy Training  12:  59.25925925925925\n",
            "Accuracy Training  13:  59.25925925925925\n",
            "Accuracy Training  14:  59.25925925925925\n",
            "Accuracy Training  15:  59.25925925925925\n",
            "Accuracy Training  16:  59.25925925925925\n",
            "Accuracy Training  17:  59.25925925925925\n",
            "Accuracy Training  18:  59.25925925925925\n",
            "Accuracy Training  19:  59.25925925925925\n",
            "Accuracy Training  20:  59.25925925925925\n",
            "Accuracy Training  21:  59.25925925925925\n",
            "Accuracy Training  22:  59.25925925925925\n",
            "Accuracy Training  23:  59.25925925925925\n",
            "Accuracy Training  24:  59.25925925925925\n",
            "Accuracy Training  25:  59.25925925925925\n",
            "Accuracy Training  26:  59.25925925925925\n",
            "Accuracy Training  27:  59.25925925925925\n",
            "Accuracy Training  28:  59.25925925925925\n",
            "Accuracy Training  29:  59.25925925925925\n",
            "Accuracy Training  30:  59.25925925925925\n",
            "Accuracy Training  31:  59.25925925925925\n",
            "Accuracy Training  32:  59.25925925925925\n",
            "Accuracy Training  33:  59.25925925925925\n",
            "Accuracy Training  34:  59.25925925925925\n",
            "Accuracy Training  35:  59.25925925925925\n",
            "Accuracy Training  36:  59.25925925925925\n",
            "Accuracy Training  37:  59.25925925925925\n",
            "Accuracy Training  38:  59.25925925925925\n",
            "Accuracy Training  39:  59.25925925925925\n",
            "Accuracy Training  40:  59.25925925925925\n",
            "Accuracy Training  41:  59.25925925925925\n",
            "Accuracy Training  42:  59.25925925925925\n",
            "Accuracy Training  43:  59.25925925925925\n",
            "Accuracy Training  44:  59.25925925925925\n",
            "Accuracy Training  45:  59.25925925925925\n",
            "Accuracy Training  46:  59.25925925925925\n",
            "Accuracy Training  47:  59.25925925925925\n",
            "Accuracy Training  48:  59.25925925925925\n",
            "Accuracy Training  49:  59.25925925925925\n",
            "Accuracy Training  50:  59.25925925925925\n",
            "Accuracy Validation  :  61.56716417910447\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.706897  0.442446  0.544248    278.0\n",
            "1             0.571823  0.802326  0.667742    258.0\n",
            "avg / total   0.641880  0.615672  0.603691    536.0\n",
            "\n",
            "Iteration  3 :\n",
            "\n",
            "Accuracy Training  1:  59.25925925925925\n",
            "Accuracy Training  2:  59.25925925925925\n",
            "Accuracy Training  3:  59.25925925925925\n",
            "Accuracy Training  4:  59.25925925925925\n",
            "Accuracy Training  5:  59.25925925925925\n",
            "Accuracy Training  6:  59.25925925925925\n",
            "Accuracy Training  7:  59.25925925925925\n",
            "Accuracy Training  8:  59.25925925925925\n",
            "Accuracy Training  9:  59.25925925925925\n",
            "Accuracy Training  10:  59.25925925925925\n",
            "Accuracy Training  11:  59.25925925925925\n",
            "Accuracy Training  12:  59.25925925925925\n",
            "Accuracy Training  13:  59.25925925925925\n",
            "Accuracy Training  14:  59.25925925925925\n",
            "Accuracy Training  15:  59.25925925925925\n",
            "Accuracy Training  16:  59.25925925925925\n",
            "Accuracy Training  17:  59.25925925925925\n",
            "Accuracy Training  18:  59.25925925925925\n",
            "Accuracy Training  19:  59.25925925925925\n",
            "Accuracy Training  20:  59.25925925925925\n",
            "Accuracy Training  21:  59.25925925925925\n",
            "Accuracy Training  22:  59.25925925925925\n",
            "Accuracy Training  23:  59.25925925925925\n",
            "Accuracy Training  24:  59.25925925925925\n",
            "Accuracy Training  25:  59.25925925925925\n",
            "Accuracy Training  26:  59.25925925925925\n",
            "Accuracy Training  27:  59.25925925925925\n",
            "Accuracy Training  28:  59.25925925925925\n",
            "Accuracy Training  29:  59.25925925925925\n",
            "Accuracy Training  30:  59.25925925925925\n",
            "Accuracy Training  31:  59.25925925925925\n",
            "Accuracy Training  32:  59.25925925925925\n",
            "Accuracy Training  33:  59.25925925925925\n",
            "Accuracy Training  34:  59.25925925925925\n",
            "Accuracy Training  35:  59.25925925925925\n",
            "Accuracy Training  36:  59.25925925925925\n",
            "Accuracy Training  37:  59.25925925925925\n",
            "Accuracy Training  38:  59.25925925925925\n",
            "Accuracy Training  39:  59.25925925925925\n",
            "Accuracy Training  40:  59.25925925925925\n",
            "Accuracy Training  41:  59.25925925925925\n",
            "Accuracy Training  42:  59.25925925925925\n",
            "Accuracy Training  43:  59.25925925925925\n",
            "Accuracy Training  44:  59.25925925925925\n",
            "Accuracy Training  45:  59.25925925925925\n",
            "Accuracy Training  46:  59.25925925925925\n",
            "Accuracy Training  47:  59.25925925925925\n",
            "Accuracy Training  48:  59.25925925925925\n",
            "Accuracy Training  49:  59.25925925925925\n",
            "Accuracy Training  50:  59.25925925925925\n",
            "Accuracy Validation  :  61.56716417910447\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.706897  0.442446  0.544248    278.0\n",
            "1             0.571823  0.802326  0.667742    258.0\n",
            "avg / total   0.641880  0.615672  0.603691    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>\\tprecision\\trecall\\tf1-score\\tsupport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0\\t0.7068965517241379\\t0.44244604316546765\\t0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1\\t0.5718232044198895\\t0.8023255813953488\\t0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>avg / total\\t0.641879903208287\\t0.615671641791...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>\\tprecision\\trecall\\tf1-score\\tsupport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0\\t0.7068965517241379\\t0.44244604316546765\\t0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1\\t0.5718232044198895\\t0.8023255813953488\\t0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>avg / total\\t0.641879903208287\\t0.615671641791...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-precision-recall-\"f1-score\"-support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0-0.7068965517241379-0.44244604316546765-0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1-0.5718232044198895-0.8023255813953488-0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>avg / total-0.641879903208287-0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-precision-recall-\"f1-score\"-support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0-0.7068965517241379-0.44244604316546765-0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1-0.5718232044198895-0.8023255813953488-0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>avg / total-0.641879903208287-0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ;precision;recall;f1-score;support\n",
              "0   0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "1   1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "2   avg / total;0.641879903208287;0.61567164179104...\n",
              "3                  ;precision;recall;f1-score;support\n",
              "4   0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "5   1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "6   avg / total;0.641879903208287;0.61567164179104...\n",
              "7                  ;precision;recall;f1-score;support\n",
              "8   0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "9   1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "10  avg / total;0.641879903208287;0.61567164179104...\n",
              "11                 ;precision;recall;f1-score;support\n",
              "12  0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "13  1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "14  avg / total;0.641879903208287;0.61567164179104...\n",
              "15                 ;precision;recall;f1-score;support\n",
              "16  0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "17  1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "18  avg / total;0.641879903208287;0.61567164179104...\n",
              "19                 ;precision;recall;f1-score;support\n",
              "20  0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "21  1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "22  avg / total;0.641879903208287;0.61567164179104...\n",
              "23             \\tprecision\\trecall\\tf1-score\\tsupport\n",
              "24  0\\t0.7068965517241379\\t0.44244604316546765\\t0....\n",
              "25  1\\t0.5718232044198895\\t0.8023255813953488\\t0.6...\n",
              "26  avg / total\\t0.641879903208287\\t0.615671641791...\n",
              "27             \\tprecision\\trecall\\tf1-score\\tsupport\n",
              "28  0\\t0.7068965517241379\\t0.44244604316546765\\t0....\n",
              "29  1\\t0.5718232044198895\\t0.8023255813953488\\t0.6...\n",
              "30  avg / total\\t0.641879903208287\\t0.615671641791...\n",
              "31               -precision-recall-\"f1-score\"-support\n",
              "32  0-0.7068965517241379-0.44244604316546765-0.544...\n",
              "33  1-0.5718232044198895-0.8023255813953488-0.6677...\n",
              "34  avg / total-0.641879903208287-0.61567164179104...\n",
              "35               -precision-recall-\"f1-score\"-support\n",
              "36  0-0.7068965517241379-0.44244604316546765-0.544...\n",
              "37  1-0.5718232044198895-0.8023255813953488-0.6677...\n",
              "38  avg / total-0.641879903208287-0.61567164179104...\n",
              "39                 ;precision;recall;f1-score;support\n",
              "40  0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "41  1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "42  avg / total;0.641879903208287;0.61567164179104..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-in19QQiERdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f3c4fe2-2586-49ef-a471-308e01481698"
      },
      "source": [
        "poly()\n",
        "show2 = pd.read_csv('PolyReport_50_2.csv')\n",
        "show2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  1 :\n",
            "\n",
            "Accuracy Training  1:  82.4074074074074\n",
            "Accuracy Training  2:  82.4074074074074\n",
            "Accuracy Training  3:  82.4074074074074\n",
            "Accuracy Training  4:  82.4074074074074\n",
            "Accuracy Training  5:  82.4074074074074\n",
            "Accuracy Training  6:  82.4074074074074\n",
            "Accuracy Training  7:  82.4074074074074\n",
            "Accuracy Training  8:  82.4074074074074\n",
            "Accuracy Training  9:  82.4074074074074\n",
            "Accuracy Training  10:  82.4074074074074\n",
            "Accuracy Training  11:  82.4074074074074\n",
            "Accuracy Training  12:  82.4074074074074\n",
            "Accuracy Training  13:  82.4074074074074\n",
            "Accuracy Training  14:  82.4074074074074\n",
            "Accuracy Training  15:  82.4074074074074\n",
            "Accuracy Training  16:  82.4074074074074\n",
            "Accuracy Training  17:  82.4074074074074\n",
            "Accuracy Training  18:  82.4074074074074\n",
            "Accuracy Training  19:  82.4074074074074\n",
            "Accuracy Training  20:  82.4074074074074\n",
            "Accuracy Training  21:  82.4074074074074\n",
            "Accuracy Training  22:  82.4074074074074\n",
            "Accuracy Training  23:  82.4074074074074\n",
            "Accuracy Training  24:  82.4074074074074\n",
            "Accuracy Training  25:  82.4074074074074\n",
            "Accuracy Training  26:  82.4074074074074\n",
            "Accuracy Training  27:  82.4074074074074\n",
            "Accuracy Training  28:  82.4074074074074\n",
            "Accuracy Training  29:  82.4074074074074\n",
            "Accuracy Training  30:  82.4074074074074\n",
            "Accuracy Training  31:  82.4074074074074\n",
            "Accuracy Training  32:  82.4074074074074\n",
            "Accuracy Training  33:  82.4074074074074\n",
            "Accuracy Training  34:  82.4074074074074\n",
            "Accuracy Training  35:  82.4074074074074\n",
            "Accuracy Training  36:  82.4074074074074\n",
            "Accuracy Training  37:  82.4074074074074\n",
            "Accuracy Training  38:  82.4074074074074\n",
            "Accuracy Training  39:  82.4074074074074\n",
            "Accuracy Training  40:  82.4074074074074\n",
            "Accuracy Training  41:  82.4074074074074\n",
            "Accuracy Training  42:  82.4074074074074\n",
            "Accuracy Training  43:  82.4074074074074\n",
            "Accuracy Training  44:  82.4074074074074\n",
            "Accuracy Training  45:  82.4074074074074\n",
            "Accuracy Training  46:  82.4074074074074\n",
            "Accuracy Training  47:  82.4074074074074\n",
            "Accuracy Training  48:  82.4074074074074\n",
            "Accuracy Training  49:  82.4074074074074\n",
            "Accuracy Training  50:  82.4074074074074\n",
            "Accuracy Validation  :  83.5820895522388\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.975000  0.701439  0.815900    278.0\n",
            "1             0.752976  0.980620  0.851852    258.0\n",
            "avg / total   0.868130  0.835821  0.833205    536.0\n",
            "\n",
            "Iteration  2 :\n",
            "\n",
            "Accuracy Training  1:  82.4074074074074\n",
            "Accuracy Training  2:  82.4074074074074\n",
            "Accuracy Training  3:  82.4074074074074\n",
            "Accuracy Training  4:  82.4074074074074\n",
            "Accuracy Training  5:  82.4074074074074\n",
            "Accuracy Training  6:  82.4074074074074\n",
            "Accuracy Training  7:  82.4074074074074\n",
            "Accuracy Training  8:  82.4074074074074\n",
            "Accuracy Training  9:  82.4074074074074\n",
            "Accuracy Training  10:  82.4074074074074\n",
            "Accuracy Training  11:  82.4074074074074\n",
            "Accuracy Training  12:  82.4074074074074\n",
            "Accuracy Training  13:  82.4074074074074\n",
            "Accuracy Training  14:  82.4074074074074\n",
            "Accuracy Training  15:  82.4074074074074\n",
            "Accuracy Training  16:  82.4074074074074\n",
            "Accuracy Training  17:  82.4074074074074\n",
            "Accuracy Training  18:  82.4074074074074\n",
            "Accuracy Training  19:  82.4074074074074\n",
            "Accuracy Training  20:  82.4074074074074\n",
            "Accuracy Training  21:  82.4074074074074\n",
            "Accuracy Training  22:  82.4074074074074\n",
            "Accuracy Training  23:  82.4074074074074\n",
            "Accuracy Training  24:  82.4074074074074\n",
            "Accuracy Training  25:  82.4074074074074\n",
            "Accuracy Training  26:  82.4074074074074\n",
            "Accuracy Training  27:  82.4074074074074\n",
            "Accuracy Training  28:  82.4074074074074\n",
            "Accuracy Training  29:  82.4074074074074\n",
            "Accuracy Training  30:  82.4074074074074\n",
            "Accuracy Training  31:  82.4074074074074\n",
            "Accuracy Training  32:  82.4074074074074\n",
            "Accuracy Training  33:  82.4074074074074\n",
            "Accuracy Training  34:  82.4074074074074\n",
            "Accuracy Training  35:  82.4074074074074\n",
            "Accuracy Training  36:  82.4074074074074\n",
            "Accuracy Training  37:  82.4074074074074\n",
            "Accuracy Training  38:  82.4074074074074\n",
            "Accuracy Training  39:  82.4074074074074\n",
            "Accuracy Training  40:  82.4074074074074\n",
            "Accuracy Training  41:  82.4074074074074\n",
            "Accuracy Training  42:  82.4074074074074\n",
            "Accuracy Training  43:  82.4074074074074\n",
            "Accuracy Training  44:  82.4074074074074\n",
            "Accuracy Training  45:  82.4074074074074\n",
            "Accuracy Training  46:  82.4074074074074\n",
            "Accuracy Training  47:  82.4074074074074\n",
            "Accuracy Training  48:  82.4074074074074\n",
            "Accuracy Training  49:  82.4074074074074\n",
            "Accuracy Training  50:  82.4074074074074\n",
            "Accuracy Validation  :  83.5820895522388\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.975000  0.701439  0.815900    278.0\n",
            "1             0.752976  0.980620  0.851852    258.0\n",
            "avg / total   0.868130  0.835821  0.833205    536.0\n",
            "\n",
            "Iteration  3 :\n",
            "\n",
            "Accuracy Training  1:  82.4074074074074\n",
            "Accuracy Training  2:  82.4074074074074\n",
            "Accuracy Training  3:  82.4074074074074\n",
            "Accuracy Training  4:  82.4074074074074\n",
            "Accuracy Training  5:  82.4074074074074\n",
            "Accuracy Training  6:  82.4074074074074\n",
            "Accuracy Training  7:  82.4074074074074\n",
            "Accuracy Training  8:  82.4074074074074\n",
            "Accuracy Training  9:  82.4074074074074\n",
            "Accuracy Training  10:  82.4074074074074\n",
            "Accuracy Training  11:  82.4074074074074\n",
            "Accuracy Training  12:  82.4074074074074\n",
            "Accuracy Training  13:  82.4074074074074\n",
            "Accuracy Training  14:  82.4074074074074\n",
            "Accuracy Training  15:  82.4074074074074\n",
            "Accuracy Training  16:  82.4074074074074\n",
            "Accuracy Training  17:  82.4074074074074\n",
            "Accuracy Training  18:  82.4074074074074\n",
            "Accuracy Training  19:  82.4074074074074\n",
            "Accuracy Training  20:  82.4074074074074\n",
            "Accuracy Training  21:  82.4074074074074\n",
            "Accuracy Training  22:  82.4074074074074\n",
            "Accuracy Training  23:  82.4074074074074\n",
            "Accuracy Training  24:  82.4074074074074\n",
            "Accuracy Training  25:  82.4074074074074\n",
            "Accuracy Training  26:  82.4074074074074\n",
            "Accuracy Training  27:  82.4074074074074\n",
            "Accuracy Training  28:  82.4074074074074\n",
            "Accuracy Training  29:  82.4074074074074\n",
            "Accuracy Training  30:  82.4074074074074\n",
            "Accuracy Training  31:  82.4074074074074\n",
            "Accuracy Training  32:  82.4074074074074\n",
            "Accuracy Training  33:  82.4074074074074\n",
            "Accuracy Training  34:  82.4074074074074\n",
            "Accuracy Training  35:  82.4074074074074\n",
            "Accuracy Training  36:  82.4074074074074\n",
            "Accuracy Training  37:  82.4074074074074\n",
            "Accuracy Training  38:  82.4074074074074\n",
            "Accuracy Training  39:  82.4074074074074\n",
            "Accuracy Training  40:  82.4074074074074\n",
            "Accuracy Training  41:  82.4074074074074\n",
            "Accuracy Training  42:  82.4074074074074\n",
            "Accuracy Training  43:  82.4074074074074\n",
            "Accuracy Training  44:  82.4074074074074\n",
            "Accuracy Training  45:  82.4074074074074\n",
            "Accuracy Training  46:  82.4074074074074\n",
            "Accuracy Training  47:  82.4074074074074\n",
            "Accuracy Training  48:  82.4074074074074\n",
            "Accuracy Training  49:  82.4074074074074\n",
            "Accuracy Training  50:  82.4074074074074\n",
            "Accuracy Validation  :  83.5820895522388\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.975000  0.701439  0.815900    278.0\n",
            "1             0.752976  0.980620  0.851852    258.0\n",
            "avg / total   0.868130  0.835821  0.833205    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.975;0.7014388489208633;0.8158995815899581;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.7529761904761905;0.9806201550387597;0.8518...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.8681303304904052;0.8358208955223...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.975;0.7014388489208633;0.8158995815899581;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.7529761904761905;0.9806201550387597;0.8518...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.8681303304904052;0.8358208955223...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ;precision;recall;f1-score;support\n",
              "0  0;0.975;0.7014388489208633;0.8158995815899581;...\n",
              "1  1;0.7529761904761905;0.9806201550387597;0.8518...\n",
              "2  avg / total;0.8681303304904052;0.8358208955223...\n",
              "3                 ;precision;recall;f1-score;support\n",
              "4  0;0.975;0.7014388489208633;0.8158995815899581;...\n",
              "5  1;0.7529761904761905;0.9806201550387597;0.8518...\n",
              "6  avg / total;0.8681303304904052;0.8358208955223..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwsKD8oEY1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5f2f75e-6f87-411e-d4d7-2aefd771ab08"
      },
      "source": [
        "gaussian()\n",
        "show3 = pd.read_csv('GaussianReport_50_2.csv')\n",
        "show3"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  1 :\n",
            "\n",
            "Accuracy Training  1:  82.4074074074074\n",
            "Accuracy Training  2:  82.4074074074074\n",
            "Accuracy Training  3:  82.4074074074074\n",
            "Accuracy Training  4:  82.4074074074074\n",
            "Accuracy Training  5:  82.4074074074074\n",
            "Accuracy Training  6:  82.4074074074074\n",
            "Accuracy Training  7:  82.4074074074074\n",
            "Accuracy Training  8:  82.4074074074074\n",
            "Accuracy Training  9:  82.4074074074074\n",
            "Accuracy Training  10:  82.4074074074074\n",
            "Accuracy Training  11:  82.4074074074074\n",
            "Accuracy Training  12:  82.4074074074074\n",
            "Accuracy Training  13:  82.4074074074074\n",
            "Accuracy Training  14:  82.4074074074074\n",
            "Accuracy Training  15:  82.4074074074074\n",
            "Accuracy Training  16:  82.4074074074074\n",
            "Accuracy Training  17:  82.4074074074074\n",
            "Accuracy Training  18:  82.4074074074074\n",
            "Accuracy Training  19:  82.4074074074074\n",
            "Accuracy Training  20:  82.4074074074074\n",
            "Accuracy Training  21:  82.4074074074074\n",
            "Accuracy Training  22:  82.4074074074074\n",
            "Accuracy Training  23:  82.4074074074074\n",
            "Accuracy Training  24:  82.4074074074074\n",
            "Accuracy Training  25:  82.4074074074074\n",
            "Accuracy Training  26:  82.4074074074074\n",
            "Accuracy Training  27:  82.4074074074074\n",
            "Accuracy Training  28:  82.4074074074074\n",
            "Accuracy Training  29:  82.4074074074074\n",
            "Accuracy Training  30:  82.4074074074074\n",
            "Accuracy Training  31:  82.4074074074074\n",
            "Accuracy Training  32:  82.4074074074074\n",
            "Accuracy Training  33:  82.4074074074074\n",
            "Accuracy Training  34:  82.4074074074074\n",
            "Accuracy Training  35:  82.4074074074074\n",
            "Accuracy Training  36:  82.4074074074074\n",
            "Accuracy Training  37:  82.4074074074074\n",
            "Accuracy Training  38:  82.4074074074074\n",
            "Accuracy Training  39:  82.4074074074074\n",
            "Accuracy Training  40:  82.4074074074074\n",
            "Accuracy Training  41:  82.4074074074074\n",
            "Accuracy Training  42:  82.4074074074074\n",
            "Accuracy Training  43:  82.4074074074074\n",
            "Accuracy Training  44:  82.4074074074074\n",
            "Accuracy Training  45:  82.4074074074074\n",
            "Accuracy Training  46:  82.4074074074074\n",
            "Accuracy Training  47:  82.4074074074074\n",
            "Accuracy Training  48:  82.4074074074074\n",
            "Accuracy Training  49:  82.4074074074074\n",
            "Accuracy Training  50:  82.4074074074074\n",
            "Accuracy Validation  :  83.3955223880597\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.965517  0.705036  0.814969    278.0\n",
            "1             0.753754  0.972868  0.849408    258.0\n",
            "avg / total   0.863586  0.833955  0.831546    536.0\n",
            "\n",
            "Iteration  2 :\n",
            "\n",
            "Accuracy Training  1:  82.4074074074074\n",
            "Accuracy Training  2:  82.4074074074074\n",
            "Accuracy Training  3:  82.4074074074074\n",
            "Accuracy Training  4:  82.4074074074074\n",
            "Accuracy Training  5:  82.4074074074074\n",
            "Accuracy Training  6:  82.4074074074074\n",
            "Accuracy Training  7:  82.4074074074074\n",
            "Accuracy Training  8:  82.4074074074074\n",
            "Accuracy Training  9:  82.4074074074074\n",
            "Accuracy Training  10:  82.4074074074074\n",
            "Accuracy Training  11:  82.4074074074074\n",
            "Accuracy Training  12:  82.4074074074074\n",
            "Accuracy Training  13:  82.4074074074074\n",
            "Accuracy Training  14:  82.4074074074074\n",
            "Accuracy Training  15:  82.4074074074074\n",
            "Accuracy Training  16:  82.4074074074074\n",
            "Accuracy Training  17:  82.4074074074074\n",
            "Accuracy Training  18:  82.4074074074074\n",
            "Accuracy Training  19:  82.4074074074074\n",
            "Accuracy Training  20:  82.4074074074074\n",
            "Accuracy Training  21:  82.4074074074074\n",
            "Accuracy Training  22:  82.4074074074074\n",
            "Accuracy Training  23:  82.4074074074074\n",
            "Accuracy Training  24:  82.4074074074074\n",
            "Accuracy Training  25:  82.4074074074074\n",
            "Accuracy Training  26:  82.4074074074074\n",
            "Accuracy Training  27:  82.4074074074074\n",
            "Accuracy Training  28:  82.4074074074074\n",
            "Accuracy Training  29:  82.4074074074074\n",
            "Accuracy Training  30:  82.4074074074074\n",
            "Accuracy Training  31:  82.4074074074074\n",
            "Accuracy Training  32:  82.4074074074074\n",
            "Accuracy Training  33:  82.4074074074074\n",
            "Accuracy Training  34:  82.4074074074074\n",
            "Accuracy Training  35:  82.4074074074074\n",
            "Accuracy Training  36:  82.4074074074074\n",
            "Accuracy Training  37:  82.4074074074074\n",
            "Accuracy Training  38:  82.4074074074074\n",
            "Accuracy Training  39:  82.4074074074074\n",
            "Accuracy Training  40:  82.4074074074074\n",
            "Accuracy Training  41:  82.4074074074074\n",
            "Accuracy Training  42:  82.4074074074074\n",
            "Accuracy Training  43:  82.4074074074074\n",
            "Accuracy Training  44:  82.4074074074074\n",
            "Accuracy Training  45:  82.4074074074074\n",
            "Accuracy Training  46:  82.4074074074074\n",
            "Accuracy Training  47:  82.4074074074074\n",
            "Accuracy Training  48:  82.4074074074074\n",
            "Accuracy Training  49:  82.4074074074074\n",
            "Accuracy Training  50:  82.4074074074074\n",
            "Accuracy Validation  :  83.3955223880597\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.965517  0.705036  0.814969    278.0\n",
            "1             0.753754  0.972868  0.849408    258.0\n",
            "avg / total   0.863586  0.833955  0.831546    536.0\n",
            "\n",
            "Iteration  3 :\n",
            "\n",
            "Accuracy Training  1:  82.4074074074074\n",
            "Accuracy Training  2:  82.4074074074074\n",
            "Accuracy Training  3:  82.4074074074074\n",
            "Accuracy Training  4:  82.4074074074074\n",
            "Accuracy Training  5:  82.4074074074074\n",
            "Accuracy Training  6:  82.4074074074074\n",
            "Accuracy Training  7:  82.4074074074074\n",
            "Accuracy Training  8:  82.4074074074074\n",
            "Accuracy Training  9:  82.4074074074074\n",
            "Accuracy Training  10:  82.4074074074074\n",
            "Accuracy Training  11:  82.4074074074074\n",
            "Accuracy Training  12:  82.4074074074074\n",
            "Accuracy Training  13:  82.4074074074074\n",
            "Accuracy Training  14:  82.4074074074074\n",
            "Accuracy Training  15:  82.4074074074074\n",
            "Accuracy Training  16:  82.4074074074074\n",
            "Accuracy Training  17:  82.4074074074074\n",
            "Accuracy Training  18:  82.4074074074074\n",
            "Accuracy Training  19:  82.4074074074074\n",
            "Accuracy Training  20:  82.4074074074074\n",
            "Accuracy Training  21:  82.4074074074074\n",
            "Accuracy Training  22:  82.4074074074074\n",
            "Accuracy Training  23:  82.4074074074074\n",
            "Accuracy Training  24:  82.4074074074074\n",
            "Accuracy Training  25:  82.4074074074074\n",
            "Accuracy Training  26:  82.4074074074074\n",
            "Accuracy Training  27:  82.4074074074074\n",
            "Accuracy Training  28:  82.4074074074074\n",
            "Accuracy Training  29:  82.4074074074074\n",
            "Accuracy Training  30:  82.4074074074074\n",
            "Accuracy Training  31:  82.4074074074074\n",
            "Accuracy Training  32:  82.4074074074074\n",
            "Accuracy Training  33:  82.4074074074074\n",
            "Accuracy Training  34:  82.4074074074074\n",
            "Accuracy Training  35:  82.4074074074074\n",
            "Accuracy Training  36:  82.4074074074074\n",
            "Accuracy Training  37:  82.4074074074074\n",
            "Accuracy Training  38:  82.4074074074074\n",
            "Accuracy Training  39:  82.4074074074074\n",
            "Accuracy Training  40:  82.4074074074074\n",
            "Accuracy Training  41:  82.4074074074074\n",
            "Accuracy Training  42:  82.4074074074074\n",
            "Accuracy Training  43:  82.4074074074074\n",
            "Accuracy Training  44:  82.4074074074074\n",
            "Accuracy Training  45:  82.4074074074074\n",
            "Accuracy Training  46:  82.4074074074074\n",
            "Accuracy Training  47:  82.4074074074074\n",
            "Accuracy Training  48:  82.4074074074074\n",
            "Accuracy Training  49:  82.4074074074074\n",
            "Accuracy Training  50:  82.4074074074074\n",
            "Accuracy Validation  :  83.3955223880597\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.965517  0.705036  0.814969    278.0\n",
            "1             0.753754  0.972868  0.849408    258.0\n",
            "avg / total   0.863586  0.833955  0.831546    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.9655172413793104;0.7050359712230215;0.8149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.7537537537537538;0.9728682170542635;0.8494...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.8635863089028298;0.8339552238805...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.9655172413793104;0.7050359712230215;0.8149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.7537537537537538;0.9728682170542635;0.8494...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.8635863089028298;0.8339552238805...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ;precision;recall;f1-score;support\n",
              "0  0;0.9655172413793104;0.7050359712230215;0.8149...\n",
              "1  1;0.7537537537537538;0.9728682170542635;0.8494...\n",
              "2  avg / total;0.8635863089028298;0.8339552238805...\n",
              "3                 ;precision;recall;f1-score;support\n",
              "4  0;0.9655172413793104;0.7050359712230215;0.8149...\n",
              "5  1;0.7537537537537538;0.9728682170542635;0.8494...\n",
              "6  avg / total;0.8635863089028298;0.8339552238805..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3xKgtY8EYZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cfcd474-64f2-46b4-bdaf-4a4a9ddc0d8b"
      },
      "source": [
        "sigmoid()\n",
        "show4 = pd.read_csv('SigmoidReport_50_2.csv')\n",
        "show4"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  1 :\n",
            "\n",
            "Accuracy Training  1:  50.92592592592593\n",
            "Accuracy Training  2:  50.92592592592593\n",
            "Accuracy Training  3:  50.92592592592593\n",
            "Accuracy Training  4:  50.92592592592593\n",
            "Accuracy Training  5:  50.92592592592593\n",
            "Accuracy Training  6:  50.92592592592593\n",
            "Accuracy Training  7:  50.92592592592593\n",
            "Accuracy Training  8:  50.92592592592593\n",
            "Accuracy Training  9:  50.92592592592593\n",
            "Accuracy Training  10:  50.92592592592593\n",
            "Accuracy Training  11:  50.92592592592593\n",
            "Accuracy Training  12:  50.92592592592593\n",
            "Accuracy Training  13:  50.92592592592593\n",
            "Accuracy Training  14:  50.92592592592593\n",
            "Accuracy Training  15:  50.92592592592593\n",
            "Accuracy Training  16:  50.92592592592593\n",
            "Accuracy Training  17:  50.92592592592593\n",
            "Accuracy Training  18:  50.92592592592593\n",
            "Accuracy Training  19:  50.92592592592593\n",
            "Accuracy Training  20:  50.92592592592593\n",
            "Accuracy Training  21:  50.92592592592593\n",
            "Accuracy Training  22:  50.92592592592593\n",
            "Accuracy Training  23:  50.92592592592593\n",
            "Accuracy Training  24:  50.92592592592593\n",
            "Accuracy Training  25:  50.92592592592593\n",
            "Accuracy Training  26:  50.92592592592593\n",
            "Accuracy Training  27:  50.92592592592593\n",
            "Accuracy Training  28:  50.92592592592593\n",
            "Accuracy Training  29:  50.92592592592593\n",
            "Accuracy Training  30:  50.92592592592593\n",
            "Accuracy Training  31:  50.92592592592593\n",
            "Accuracy Training  32:  50.92592592592593\n",
            "Accuracy Training  33:  50.92592592592593\n",
            "Accuracy Training  34:  50.92592592592593\n",
            "Accuracy Training  35:  50.92592592592593\n",
            "Accuracy Training  36:  50.92592592592593\n",
            "Accuracy Training  37:  50.92592592592593\n",
            "Accuracy Training  38:  50.92592592592593\n",
            "Accuracy Training  39:  50.92592592592593\n",
            "Accuracy Training  40:  50.92592592592593\n",
            "Accuracy Training  41:  50.92592592592593\n",
            "Accuracy Training  42:  50.92592592592593\n",
            "Accuracy Training  43:  50.92592592592593\n",
            "Accuracy Training  44:  50.92592592592593\n",
            "Accuracy Training  45:  50.92592592592593\n",
            "Accuracy Training  46:  50.92592592592593\n",
            "Accuracy Training  47:  50.92592592592593\n",
            "Accuracy Training  48:  50.92592592592593\n",
            "Accuracy Training  49:  50.92592592592593\n",
            "Accuracy Training  50:  50.92592592592593\n",
            "Accuracy Validation  :  51.865671641791046\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.518657  1.000000  0.683047    278.0\n",
            "1             0.000000  0.000000  0.000000    258.0\n",
            "avg / total   0.269005  0.518657  0.354267    536.0\n",
            "\n",
            "Iteration  2 :\n",
            "\n",
            "Accuracy Training  1:  50.92592592592593\n",
            "Accuracy Training  2:  50.92592592592593\n",
            "Accuracy Training  3:  50.92592592592593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Training  4:  50.92592592592593\n",
            "Accuracy Training  5:  50.92592592592593\n",
            "Accuracy Training  6:  50.92592592592593\n",
            "Accuracy Training  7:  50.92592592592593\n",
            "Accuracy Training  8:  50.92592592592593\n",
            "Accuracy Training  9:  50.92592592592593\n",
            "Accuracy Training  10:  50.92592592592593\n",
            "Accuracy Training  11:  50.92592592592593\n",
            "Accuracy Training  12:  50.92592592592593\n",
            "Accuracy Training  13:  50.92592592592593\n",
            "Accuracy Training  14:  50.92592592592593\n",
            "Accuracy Training  15:  50.92592592592593\n",
            "Accuracy Training  16:  50.92592592592593\n",
            "Accuracy Training  17:  50.92592592592593\n",
            "Accuracy Training  18:  50.92592592592593\n",
            "Accuracy Training  19:  50.92592592592593\n",
            "Accuracy Training  20:  50.92592592592593\n",
            "Accuracy Training  21:  50.92592592592593\n",
            "Accuracy Training  22:  50.92592592592593\n",
            "Accuracy Training  23:  50.92592592592593\n",
            "Accuracy Training  24:  50.92592592592593\n",
            "Accuracy Training  25:  50.92592592592593\n",
            "Accuracy Training  26:  50.92592592592593\n",
            "Accuracy Training  27:  50.92592592592593\n",
            "Accuracy Training  28:  50.92592592592593\n",
            "Accuracy Training  29:  50.92592592592593\n",
            "Accuracy Training  30:  50.92592592592593\n",
            "Accuracy Training  31:  50.92592592592593\n",
            "Accuracy Training  32:  50.92592592592593\n",
            "Accuracy Training  33:  50.92592592592593\n",
            "Accuracy Training  34:  50.92592592592593\n",
            "Accuracy Training  35:  50.92592592592593\n",
            "Accuracy Training  36:  50.92592592592593\n",
            "Accuracy Training  37:  50.92592592592593\n",
            "Accuracy Training  38:  50.92592592592593\n",
            "Accuracy Training  39:  50.92592592592593\n",
            "Accuracy Training  40:  50.92592592592593\n",
            "Accuracy Training  41:  50.92592592592593\n",
            "Accuracy Training  42:  50.92592592592593\n",
            "Accuracy Training  43:  50.92592592592593\n",
            "Accuracy Training  44:  50.92592592592593\n",
            "Accuracy Training  45:  50.92592592592593\n",
            "Accuracy Training  46:  50.92592592592593\n",
            "Accuracy Training  47:  50.92592592592593\n",
            "Accuracy Training  48:  50.92592592592593\n",
            "Accuracy Training  49:  50.92592592592593\n",
            "Accuracy Training  50:  50.92592592592593\n",
            "Accuracy Validation  :  51.865671641791046\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.518657  1.000000  0.683047    278.0\n",
            "1             0.000000  0.000000  0.000000    258.0\n",
            "avg / total   0.269005  0.518657  0.354267    536.0\n",
            "\n",
            "Iteration  3 :\n",
            "\n",
            "Accuracy Training  1:  50.92592592592593\n",
            "Accuracy Training  2:  50.92592592592593\n",
            "Accuracy Training  3:  50.92592592592593\n",
            "Accuracy Training  4:  50.92592592592593\n",
            "Accuracy Training  5:  50.92592592592593\n",
            "Accuracy Training  6:  50.92592592592593\n",
            "Accuracy Training  7:  50.92592592592593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Training  8:  50.92592592592593\n",
            "Accuracy Training  9:  50.92592592592593\n",
            "Accuracy Training  10:  50.92592592592593\n",
            "Accuracy Training  11:  50.92592592592593\n",
            "Accuracy Training  12:  50.92592592592593\n",
            "Accuracy Training  13:  50.92592592592593\n",
            "Accuracy Training  14:  50.92592592592593\n",
            "Accuracy Training  15:  50.92592592592593\n",
            "Accuracy Training  16:  50.92592592592593\n",
            "Accuracy Training  17:  50.92592592592593\n",
            "Accuracy Training  18:  50.92592592592593\n",
            "Accuracy Training  19:  50.92592592592593\n",
            "Accuracy Training  20:  50.92592592592593\n",
            "Accuracy Training  21:  50.92592592592593\n",
            "Accuracy Training  22:  50.92592592592593\n",
            "Accuracy Training  23:  50.92592592592593\n",
            "Accuracy Training  24:  50.92592592592593\n",
            "Accuracy Training  25:  50.92592592592593\n",
            "Accuracy Training  26:  50.92592592592593\n",
            "Accuracy Training  27:  50.92592592592593\n",
            "Accuracy Training  28:  50.92592592592593\n",
            "Accuracy Training  29:  50.92592592592593\n",
            "Accuracy Training  30:  50.92592592592593\n",
            "Accuracy Training  31:  50.92592592592593\n",
            "Accuracy Training  32:  50.92592592592593\n",
            "Accuracy Training  33:  50.92592592592593\n",
            "Accuracy Training  34:  50.92592592592593\n",
            "Accuracy Training  35:  50.92592592592593\n",
            "Accuracy Training  36:  50.92592592592593\n",
            "Accuracy Training  37:  50.92592592592593\n",
            "Accuracy Training  38:  50.92592592592593\n",
            "Accuracy Training  39:  50.92592592592593\n",
            "Accuracy Training  40:  50.92592592592593\n",
            "Accuracy Training  41:  50.92592592592593\n",
            "Accuracy Training  42:  50.92592592592593\n",
            "Accuracy Training  43:  50.92592592592593\n",
            "Accuracy Training  44:  50.92592592592593\n",
            "Accuracy Training  45:  50.92592592592593\n",
            "Accuracy Training  46:  50.92592592592593\n",
            "Accuracy Training  47:  50.92592592592593\n",
            "Accuracy Training  48:  50.92592592592593\n",
            "Accuracy Training  49:  50.92592592592593\n",
            "Accuracy Training  50:  50.92592592592593\n",
            "Accuracy Validation  :  51.865671641791046\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.518657  1.000000  0.683047    278.0\n",
            "1             0.000000  0.000000  0.000000    258.0\n",
            "avg / total   0.269005  0.518657  0.354267    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.5186567164179104;1.0;0.6830466830466831;278.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.0;0.0;0.0;258.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.2690047894854088;0.5186567164179...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.5186567164179104;1.0;0.6830466830466831;278.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.0;0.0;0.0;258.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.2690047894854088;0.5186567164179...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ;precision;recall;f1-score;support\n",
              "0  0;0.5186567164179104;1.0;0.6830466830466831;278.0\n",
              "1                                1;0.0;0.0;0.0;258.0\n",
              "2  avg / total;0.2690047894854088;0.5186567164179...\n",
              "3                 ;precision;recall;f1-score;support\n",
              "4  0;0.5186567164179104;1.0;0.6830466830466831;278.0\n",
              "5                                1;0.0;0.0;0.0;258.0\n",
              "6  avg / total;0.2690047894854088;0.5186567164179..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCXWxmN8F2nW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "dad0e1aa-275c-49b3-bbae-6612b4dccfdd"
      },
      "source": [
        "show5 = pd.read_csv('GaussianReport_50_2.csv')\n",
        "show5"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.9655172413793104;0.7050359712230215;0.8149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.7537537537537538;0.9728682170542635;0.8494...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.8635863089028298;0.8339552238805...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.9655172413793104;0.7050359712230215;0.8149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.7537537537537538;0.9728682170542635;0.8494...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.8635863089028298;0.8339552238805...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ;precision;recall;f1-score;support\n",
              "0  0;0.9655172413793104;0.7050359712230215;0.8149...\n",
              "1  1;0.7537537537537538;0.9728682170542635;0.8494...\n",
              "2  avg / total;0.8635863089028298;0.8339552238805...\n",
              "3                 ;precision;recall;f1-score;support\n",
              "4  0;0.9655172413793104;0.7050359712230215;0.8149...\n",
              "5  1;0.7537537537537538;0.9728682170542635;0.8494...\n",
              "6  avg / total;0.8635863089028298;0.8339552238805..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}