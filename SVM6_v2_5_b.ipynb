{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM6 v2.5.b.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPFWDSC5ugkhc4brRelFKF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "leMI2hrB73Zg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4f7dd1b9-72a3-44c9-ed52-965c65e64858"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CG6uIlf_dtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "347b82db-f3a7-43c1-c5f4-29b5a7e045e6"
      },
      "source": [
        "#Importing Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split as tt, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "%matplotlib inline\n",
        "\n",
        "%cd /content/drive/My Drive/Batik/SVM/\n",
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Batik/SVM\n",
            "\u001b[0m\u001b[01;34mBatikYogya\u001b[0m/              LinearReport.csv       RsLinear3.csv\n",
            "DataGaussian.csv         nama_file.csv          RsLinear.csv\n",
            "DataTraining.csv         newDataTraining.csv    RsPolynomial.csv\n",
            "DataValidation.csv       newDataValidation.csv  RsSigmoid.csv\n",
            "GaussianReport_50_1.csv  PolyReport_50_1.csv    RsTryLinear2.csv\n",
            "GaussianReport_50_2.csv  PolyReport_50_2.csv    SigmoidReport_50_1.csv\n",
            "GaussianReport_50_3.csv  PolyReport_50_3.csv    SigmoidReport_50_2.csv\n",
            "LinearReport_50_1.csv    PrecisionTryLin.csv    SigmoidReport_50_3.csv\n",
            "LinearReport_50_2.csv    RsGauss.csv\n",
            "LinearReport_50_3.csv    RsLinear2.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctavhWPP_pWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dTrain = pd.read_csv('newDataTraining.csv')\n",
        "dValid = pd.read_csv('newDataTraining.csv')\n",
        "x = dTrain.iloc[:, 1:6].values\n",
        "y = dTrain.iloc[:, 7].values\n",
        "valDat = dValid.iloc[:, 1:6].values\n",
        "valTarget = dValid.iloc[:, 7].values\n",
        "iteration = 3\n",
        "epochs = 50\n",
        "\n",
        "def pandas_classification_report(y_true, y_pred):\n",
        "        metrics_summary = precision_recall_fscore_support(\n",
        "                y_true=y_true, \n",
        "                y_pred=y_pred)\n",
        "\n",
        "        avg = list(precision_recall_fscore_support(\n",
        "                y_true=y_true, \n",
        "                y_pred=y_pred,\n",
        "                average='weighted'))\n",
        "\n",
        "        metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
        "\n",
        "        class_report_df = pd.DataFrame(list(metrics_summary),index=metrics_sum_index)\n",
        "        support = class_report_df.loc['support']\n",
        "        total = support.sum() \n",
        "        avg[-1] = total\n",
        "        \n",
        "        # class_report_df = pd.DataFrame(index=metrics_sum_index)\n",
        "        class_report_df['avg / total'] = avg\n",
        "\n",
        "        return class_report_df.T\n",
        "\n",
        "def linear():\n",
        "  for itr in range(int(iteration)):\n",
        "    print('\\nIteration ', str(itr+1), ':\\n')\n",
        "    for epoch in range(int(epochs)):\n",
        "      model = SVC(kernel='linear')\n",
        "      x_train, x_test, y_train, y_test = tt(x,y, test_size=0.2, random_state=6)\n",
        "      model.fit(x_train, y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      accT = (np.sum(y_pred == y_test)/ y_test.size)*100\n",
        "      print('Accuracy Training  '+str(epoch+1)+': ', str(accT))\n",
        "    valPred = model.predict(valDat)\n",
        "    accV = (np.sum(valPred == valTarget)/ valTarget.size)*100\n",
        "    class_report = pandas_classification_report(valTarget, valPred)\n",
        "    print('Accuracy Validation  : ', str(accV))\n",
        "    print('Class Report         : \\n', str(class_report)) #0 as Cap, 1 as Tulis\n",
        "    class_report.to_csv('LinearReport'+'_'+str(epoch+1)+'_'+str(itr+1)+'.csv', mode='a', sep=';', encoding='utf-8', header=True)\n",
        "\n",
        "def poly():\n",
        "  for itr in range(int(iteration)):\n",
        "    print('\\nIteration ', str(itr+1), ':\\n')\n",
        "    for epoch in range(int(epochs)):\n",
        "      model = SVC(kernel='poly')\n",
        "      x_train, x_test, y_train, y_test = tt(x,y, test_size=0.2, random_state=81)\n",
        "      model.fit(x_train, y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      accT = (np.sum(y_pred == y_test)/ y_test.size)*100\n",
        "      print('Accuracy Training  '+str(epoch+1)+': ', str(accT))\n",
        "    valPred = model.predict(valDat)\n",
        "    accV = (np.sum(valPred == valTarget)/ valTarget.size)*100\n",
        "    class_report = pandas_classification_report(valTarget, valPred)\n",
        "    print('Accuracy Validation  : ', str(accV))\n",
        "    print('Class Report         : \\n', str(class_report)) #0 as Cap, 1 as Tulis\n",
        "    class_report.to_csv('PolyReport'+'_'+str(epoch+1)+'_'+str(itr+1)+'.csv', mode='a', sep=';', encoding='utf-8', header=True)\n",
        "\n",
        "\n",
        "def gaussian():\n",
        "  for itr in range(int(iteration)):\n",
        "    print('\\nIteration ', str(itr+1), ':\\n')\n",
        "    for epoch in range(int(epochs)):\n",
        "      model = SVC(kernel='rbf')\n",
        "      x_train, x_test, y_train, y_test = tt(x,y, test_size=0.2, random_state=38)\n",
        "      model.fit(x_train, y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      accT = (np.sum(y_pred == y_test)/ y_test.size)*100\n",
        "      print('Accuracy Training  '+str(epoch+1)+': ', str(accT))\n",
        "    valPred = model.predict(valDat)\n",
        "    accV = (np.sum(valPred == valTarget)/ valTarget.size)*100\n",
        "    class_report = pandas_classification_report(valTarget, valPred)\n",
        "    print('Accuracy Validation  : ', str(accV))\n",
        "    print('Class Report         : \\n', str(class_report)) #0 as Cap, 1 as Tulis\n",
        "    class_report.to_csv('GaussianReport'+'_'+str(epoch+1)+'_'+str(itr+1)+'.csv', mode='a', sep=';', encoding='utf-8', header=True)\n",
        "\n",
        "\n",
        "def sigmoid():\n",
        "  for itr in range(int(iteration)):\n",
        "    print('\\nIteration ', str(itr+1), ':\\n')\n",
        "    for epoch in range(int(epochs)):\n",
        "      model = SVC(kernel='sigmoid')\n",
        "      x_train, x_test, y_train, y_test = tt(x,y, test_size=0.2, random_state=13)\n",
        "      model.fit(x_train, y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      accT = (np.sum(y_pred == y_test)/ y_test.size)*100\n",
        "      print('Accuracy Training  '+str(epoch+1)+': ', str(accT))\n",
        "    valPred = model.predict(valDat)\n",
        "    accV = (np.sum(valPred == valTarget)/ valTarget.size)*100\n",
        "    class_report = pandas_classification_report(valTarget, valPred)\n",
        "    print('Accuracy Validation  : ', str(accV))\n",
        "    print('Class Report         : \\n', str(class_report)) #0 as Cap, 1 as Tulis\n",
        "    class_report.to_csv('SigmoidReport'+'_'+str(epoch+1)+'_'+str(itr+1)+'.csv', mode='a', sep=';', encoding='utf-8', header=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzGf8EUVALYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de58c1f3-5c2d-4f42-b21d-bb8851b34236"
      },
      "source": [
        "linear()\n",
        "show = pd.read_csv('LinearReport_50_2.csv')\n",
        "show"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  1 :\n",
            "\n",
            "Accuracy Training  1:  62.03703703703704\n",
            "Accuracy Training  2:  62.03703703703704\n",
            "Accuracy Training  3:  62.03703703703704\n",
            "Accuracy Training  4:  62.03703703703704\n",
            "Accuracy Training  5:  62.03703703703704\n",
            "Accuracy Training  6:  62.03703703703704\n",
            "Accuracy Training  7:  62.03703703703704\n",
            "Accuracy Training  8:  62.03703703703704\n",
            "Accuracy Training  9:  62.03703703703704\n",
            "Accuracy Training  10:  62.03703703703704\n",
            "Accuracy Training  11:  62.03703703703704\n",
            "Accuracy Training  12:  62.03703703703704\n",
            "Accuracy Training  13:  62.03703703703704\n",
            "Accuracy Training  14:  62.03703703703704\n",
            "Accuracy Training  15:  62.03703703703704\n",
            "Accuracy Training  16:  62.03703703703704\n",
            "Accuracy Training  17:  62.03703703703704\n",
            "Accuracy Training  18:  62.03703703703704\n",
            "Accuracy Training  19:  62.03703703703704\n",
            "Accuracy Training  20:  62.03703703703704\n",
            "Accuracy Training  21:  62.03703703703704\n",
            "Accuracy Training  22:  62.03703703703704\n",
            "Accuracy Training  23:  62.03703703703704\n",
            "Accuracy Training  24:  62.03703703703704\n",
            "Accuracy Training  25:  62.03703703703704\n",
            "Accuracy Training  26:  62.03703703703704\n",
            "Accuracy Training  27:  62.03703703703704\n",
            "Accuracy Training  28:  62.03703703703704\n",
            "Accuracy Training  29:  62.03703703703704\n",
            "Accuracy Training  30:  62.03703703703704\n",
            "Accuracy Training  31:  62.03703703703704\n",
            "Accuracy Training  32:  62.03703703703704\n",
            "Accuracy Training  33:  62.03703703703704\n",
            "Accuracy Training  34:  62.03703703703704\n",
            "Accuracy Training  35:  62.03703703703704\n",
            "Accuracy Training  36:  62.03703703703704\n",
            "Accuracy Training  37:  62.03703703703704\n",
            "Accuracy Training  38:  62.03703703703704\n",
            "Accuracy Training  39:  62.03703703703704\n",
            "Accuracy Training  40:  62.03703703703704\n",
            "Accuracy Training  41:  62.03703703703704\n",
            "Accuracy Training  42:  62.03703703703704\n",
            "Accuracy Training  43:  62.03703703703704\n",
            "Accuracy Training  44:  62.03703703703704\n",
            "Accuracy Training  45:  62.03703703703704\n",
            "Accuracy Training  46:  62.03703703703704\n",
            "Accuracy Training  47:  62.03703703703704\n",
            "Accuracy Training  48:  62.03703703703704\n",
            "Accuracy Training  49:  62.03703703703704\n",
            "Accuracy Training  50:  62.03703703703704\n",
            "Accuracy Validation  :  65.29850746268657\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.823944  0.420863  0.557143    278.0\n",
            "1             0.591371  0.903101  0.714724    258.0\n",
            "avg / total   0.711996  0.652985  0.632993    536.0\n",
            "\n",
            "Iteration  2 :\n",
            "\n",
            "Accuracy Training  1:  62.03703703703704\n",
            "Accuracy Training  2:  62.03703703703704\n",
            "Accuracy Training  3:  62.03703703703704\n",
            "Accuracy Training  4:  62.03703703703704\n",
            "Accuracy Training  5:  62.03703703703704\n",
            "Accuracy Training  6:  62.03703703703704\n",
            "Accuracy Training  7:  62.03703703703704\n",
            "Accuracy Training  8:  62.03703703703704\n",
            "Accuracy Training  9:  62.03703703703704\n",
            "Accuracy Training  10:  62.03703703703704\n",
            "Accuracy Training  11:  62.03703703703704\n",
            "Accuracy Training  12:  62.03703703703704\n",
            "Accuracy Training  13:  62.03703703703704\n",
            "Accuracy Training  14:  62.03703703703704\n",
            "Accuracy Training  15:  62.03703703703704\n",
            "Accuracy Training  16:  62.03703703703704\n",
            "Accuracy Training  17:  62.03703703703704\n",
            "Accuracy Training  18:  62.03703703703704\n",
            "Accuracy Training  19:  62.03703703703704\n",
            "Accuracy Training  20:  62.03703703703704\n",
            "Accuracy Training  21:  62.03703703703704\n",
            "Accuracy Training  22:  62.03703703703704\n",
            "Accuracy Training  23:  62.03703703703704\n",
            "Accuracy Training  24:  62.03703703703704\n",
            "Accuracy Training  25:  62.03703703703704\n",
            "Accuracy Training  26:  62.03703703703704\n",
            "Accuracy Training  27:  62.03703703703704\n",
            "Accuracy Training  28:  62.03703703703704\n",
            "Accuracy Training  29:  62.03703703703704\n",
            "Accuracy Training  30:  62.03703703703704\n",
            "Accuracy Training  31:  62.03703703703704\n",
            "Accuracy Training  32:  62.03703703703704\n",
            "Accuracy Training  33:  62.03703703703704\n",
            "Accuracy Training  34:  62.03703703703704\n",
            "Accuracy Training  35:  62.03703703703704\n",
            "Accuracy Training  36:  62.03703703703704\n",
            "Accuracy Training  37:  62.03703703703704\n",
            "Accuracy Training  38:  62.03703703703704\n",
            "Accuracy Training  39:  62.03703703703704\n",
            "Accuracy Training  40:  62.03703703703704\n",
            "Accuracy Training  41:  62.03703703703704\n",
            "Accuracy Training  42:  62.03703703703704\n",
            "Accuracy Training  43:  62.03703703703704\n",
            "Accuracy Training  44:  62.03703703703704\n",
            "Accuracy Training  45:  62.03703703703704\n",
            "Accuracy Training  46:  62.03703703703704\n",
            "Accuracy Training  47:  62.03703703703704\n",
            "Accuracy Training  48:  62.03703703703704\n",
            "Accuracy Training  49:  62.03703703703704\n",
            "Accuracy Training  50:  62.03703703703704\n",
            "Accuracy Validation  :  65.29850746268657\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.823944  0.420863  0.557143    278.0\n",
            "1             0.591371  0.903101  0.714724    258.0\n",
            "avg / total   0.711996  0.652985  0.632993    536.0\n",
            "\n",
            "Iteration  3 :\n",
            "\n",
            "Accuracy Training  1:  62.03703703703704\n",
            "Accuracy Training  2:  62.03703703703704\n",
            "Accuracy Training  3:  62.03703703703704\n",
            "Accuracy Training  4:  62.03703703703704\n",
            "Accuracy Training  5:  62.03703703703704\n",
            "Accuracy Training  6:  62.03703703703704\n",
            "Accuracy Training  7:  62.03703703703704\n",
            "Accuracy Training  8:  62.03703703703704\n",
            "Accuracy Training  9:  62.03703703703704\n",
            "Accuracy Training  10:  62.03703703703704\n",
            "Accuracy Training  11:  62.03703703703704\n",
            "Accuracy Training  12:  62.03703703703704\n",
            "Accuracy Training  13:  62.03703703703704\n",
            "Accuracy Training  14:  62.03703703703704\n",
            "Accuracy Training  15:  62.03703703703704\n",
            "Accuracy Training  16:  62.03703703703704\n",
            "Accuracy Training  17:  62.03703703703704\n",
            "Accuracy Training  18:  62.03703703703704\n",
            "Accuracy Training  19:  62.03703703703704\n",
            "Accuracy Training  20:  62.03703703703704\n",
            "Accuracy Training  21:  62.03703703703704\n",
            "Accuracy Training  22:  62.03703703703704\n",
            "Accuracy Training  23:  62.03703703703704\n",
            "Accuracy Training  24:  62.03703703703704\n",
            "Accuracy Training  25:  62.03703703703704\n",
            "Accuracy Training  26:  62.03703703703704\n",
            "Accuracy Training  27:  62.03703703703704\n",
            "Accuracy Training  28:  62.03703703703704\n",
            "Accuracy Training  29:  62.03703703703704\n",
            "Accuracy Training  30:  62.03703703703704\n",
            "Accuracy Training  31:  62.03703703703704\n",
            "Accuracy Training  32:  62.03703703703704\n",
            "Accuracy Training  33:  62.03703703703704\n",
            "Accuracy Training  34:  62.03703703703704\n",
            "Accuracy Training  35:  62.03703703703704\n",
            "Accuracy Training  36:  62.03703703703704\n",
            "Accuracy Training  37:  62.03703703703704\n",
            "Accuracy Training  38:  62.03703703703704\n",
            "Accuracy Training  39:  62.03703703703704\n",
            "Accuracy Training  40:  62.03703703703704\n",
            "Accuracy Training  41:  62.03703703703704\n",
            "Accuracy Training  42:  62.03703703703704\n",
            "Accuracy Training  43:  62.03703703703704\n",
            "Accuracy Training  44:  62.03703703703704\n",
            "Accuracy Training  45:  62.03703703703704\n",
            "Accuracy Training  46:  62.03703703703704\n",
            "Accuracy Training  47:  62.03703703703704\n",
            "Accuracy Training  48:  62.03703703703704\n",
            "Accuracy Training  49:  62.03703703703704\n",
            "Accuracy Training  50:  62.03703703703704\n",
            "Accuracy Validation  :  65.29850746268657\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.823944  0.420863  0.557143    278.0\n",
            "1             0.591371  0.903101  0.714724    258.0\n",
            "avg / total   0.711996  0.652985  0.632993    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>\\tprecision\\trecall\\tf1-score\\tsupport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0\\t0.7068965517241379\\t0.44244604316546765\\t0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1\\t0.5718232044198895\\t0.8023255813953488\\t0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>avg / total\\t0.641879903208287\\t0.615671641791...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>\\tprecision\\trecall\\tf1-score\\tsupport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0\\t0.7068965517241379\\t0.44244604316546765\\t0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1\\t0.5718232044198895\\t0.8023255813953488\\t0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>avg / total\\t0.641879903208287\\t0.615671641791...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-precision-recall-\"f1-score\"-support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0-0.7068965517241379-0.44244604316546765-0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1-0.5718232044198895-0.8023255813953488-0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>avg / total-0.641879903208287-0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-precision-recall-\"f1-score\"-support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0-0.7068965517241379-0.44244604316546765-0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1-0.5718232044198895-0.8023255813953488-0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>avg / total-0.641879903208287-0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0;0.7068965517241379;0.44244604316546765;0.544...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1;0.5718232044198895;0.8023255813953488;0.6677...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>avg / total;0.641879903208287;0.61567164179104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0;0.823943661971831;0.420863309352518;0.557142...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1;0.5913705583756346;0.9031007751937985;0.7147...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>avg / total;0.7119961606139604;0.6529850746268...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ;precision;recall;f1-score;support\n",
              "0   0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "1   1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "2   avg / total;0.641879903208287;0.61567164179104...\n",
              "3                  ;precision;recall;f1-score;support\n",
              "4   0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "5   1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "6   avg / total;0.641879903208287;0.61567164179104...\n",
              "7                  ;precision;recall;f1-score;support\n",
              "8   0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "9   1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "10  avg / total;0.641879903208287;0.61567164179104...\n",
              "11                 ;precision;recall;f1-score;support\n",
              "12  0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "13  1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "14  avg / total;0.641879903208287;0.61567164179104...\n",
              "15                 ;precision;recall;f1-score;support\n",
              "16  0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "17  1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "18  avg / total;0.641879903208287;0.61567164179104...\n",
              "19                 ;precision;recall;f1-score;support\n",
              "20  0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "21  1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "22  avg / total;0.641879903208287;0.61567164179104...\n",
              "23             \\tprecision\\trecall\\tf1-score\\tsupport\n",
              "24  0\\t0.7068965517241379\\t0.44244604316546765\\t0....\n",
              "25  1\\t0.5718232044198895\\t0.8023255813953488\\t0.6...\n",
              "26  avg / total\\t0.641879903208287\\t0.615671641791...\n",
              "27             \\tprecision\\trecall\\tf1-score\\tsupport\n",
              "28  0\\t0.7068965517241379\\t0.44244604316546765\\t0....\n",
              "29  1\\t0.5718232044198895\\t0.8023255813953488\\t0.6...\n",
              "30  avg / total\\t0.641879903208287\\t0.615671641791...\n",
              "31               -precision-recall-\"f1-score\"-support\n",
              "32  0-0.7068965517241379-0.44244604316546765-0.544...\n",
              "33  1-0.5718232044198895-0.8023255813953488-0.6677...\n",
              "34  avg / total-0.641879903208287-0.61567164179104...\n",
              "35               -precision-recall-\"f1-score\"-support\n",
              "36  0-0.7068965517241379-0.44244604316546765-0.544...\n",
              "37  1-0.5718232044198895-0.8023255813953488-0.6677...\n",
              "38  avg / total-0.641879903208287-0.61567164179104...\n",
              "39                 ;precision;recall;f1-score;support\n",
              "40  0;0.7068965517241379;0.44244604316546765;0.544...\n",
              "41  1;0.5718232044198895;0.8023255813953488;0.6677...\n",
              "42  avg / total;0.641879903208287;0.61567164179104...\n",
              "43                 ;precision;recall;f1-score;support\n",
              "44  0;0.823943661971831;0.420863309352518;0.557142...\n",
              "45  1;0.5913705583756346;0.9031007751937985;0.7147...\n",
              "46  avg / total;0.7119961606139604;0.6529850746268..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-in19QQiERdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15d5b97d-387a-44e0-8cdc-c810c95e5d98"
      },
      "source": [
        "poly()\n",
        "show2 = pd.read_csv('PolyReport_50_2.csv')\n",
        "show2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  1 :\n",
            "\n",
            "Accuracy Training  1:  84.25925925925925\n",
            "Accuracy Training  2:  84.25925925925925\n",
            "Accuracy Training  3:  84.25925925925925\n",
            "Accuracy Training  4:  84.25925925925925\n",
            "Accuracy Training  5:  84.25925925925925\n",
            "Accuracy Training  6:  84.25925925925925\n",
            "Accuracy Training  7:  84.25925925925925\n",
            "Accuracy Training  8:  84.25925925925925\n",
            "Accuracy Training  9:  84.25925925925925\n",
            "Accuracy Training  10:  84.25925925925925\n",
            "Accuracy Training  11:  84.25925925925925\n",
            "Accuracy Training  12:  84.25925925925925\n",
            "Accuracy Training  13:  84.25925925925925\n",
            "Accuracy Training  14:  84.25925925925925\n",
            "Accuracy Training  15:  84.25925925925925\n",
            "Accuracy Training  16:  84.25925925925925\n",
            "Accuracy Training  17:  84.25925925925925\n",
            "Accuracy Training  18:  84.25925925925925\n",
            "Accuracy Training  19:  84.25925925925925\n",
            "Accuracy Training  20:  84.25925925925925\n",
            "Accuracy Training  21:  84.25925925925925\n",
            "Accuracy Training  22:  84.25925925925925\n",
            "Accuracy Training  23:  84.25925925925925\n",
            "Accuracy Training  24:  84.25925925925925\n",
            "Accuracy Training  25:  84.25925925925925\n",
            "Accuracy Training  26:  84.25925925925925\n",
            "Accuracy Training  27:  84.25925925925925\n",
            "Accuracy Training  28:  84.25925925925925\n",
            "Accuracy Training  29:  84.25925925925925\n",
            "Accuracy Training  30:  84.25925925925925\n",
            "Accuracy Training  31:  84.25925925925925\n",
            "Accuracy Training  32:  84.25925925925925\n",
            "Accuracy Training  33:  84.25925925925925\n",
            "Accuracy Training  34:  84.25925925925925\n",
            "Accuracy Training  35:  84.25925925925925\n",
            "Accuracy Training  36:  84.25925925925925\n",
            "Accuracy Training  37:  84.25925925925925\n",
            "Accuracy Training  38:  84.25925925925925\n",
            "Accuracy Training  39:  84.25925925925925\n",
            "Accuracy Training  40:  84.25925925925925\n",
            "Accuracy Training  41:  84.25925925925925\n",
            "Accuracy Training  42:  84.25925925925925\n",
            "Accuracy Training  43:  84.25925925925925\n",
            "Accuracy Training  44:  84.25925925925925\n",
            "Accuracy Training  45:  84.25925925925925\n",
            "Accuracy Training  46:  84.25925925925925\n",
            "Accuracy Training  47:  84.25925925925925\n",
            "Accuracy Training  48:  84.25925925925925\n",
            "Accuracy Training  49:  84.25925925925925\n",
            "Accuracy Training  50:  84.25925925925925\n",
            "Accuracy Validation  :  84.51492537313433\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.975610  0.719424  0.828157    278.0\n",
            "1             0.764350  0.980620  0.859083    258.0\n",
            "avg / total   0.873922  0.845149  0.843043    536.0\n",
            "\n",
            "Iteration  2 :\n",
            "\n",
            "Accuracy Training  1:  84.25925925925925\n",
            "Accuracy Training  2:  84.25925925925925\n",
            "Accuracy Training  3:  84.25925925925925\n",
            "Accuracy Training  4:  84.25925925925925\n",
            "Accuracy Training  5:  84.25925925925925\n",
            "Accuracy Training  6:  84.25925925925925\n",
            "Accuracy Training  7:  84.25925925925925\n",
            "Accuracy Training  8:  84.25925925925925\n",
            "Accuracy Training  9:  84.25925925925925\n",
            "Accuracy Training  10:  84.25925925925925\n",
            "Accuracy Training  11:  84.25925925925925\n",
            "Accuracy Training  12:  84.25925925925925\n",
            "Accuracy Training  13:  84.25925925925925\n",
            "Accuracy Training  14:  84.25925925925925\n",
            "Accuracy Training  15:  84.25925925925925\n",
            "Accuracy Training  16:  84.25925925925925\n",
            "Accuracy Training  17:  84.25925925925925\n",
            "Accuracy Training  18:  84.25925925925925\n",
            "Accuracy Training  19:  84.25925925925925\n",
            "Accuracy Training  20:  84.25925925925925\n",
            "Accuracy Training  21:  84.25925925925925\n",
            "Accuracy Training  22:  84.25925925925925\n",
            "Accuracy Training  23:  84.25925925925925\n",
            "Accuracy Training  24:  84.25925925925925\n",
            "Accuracy Training  25:  84.25925925925925\n",
            "Accuracy Training  26:  84.25925925925925\n",
            "Accuracy Training  27:  84.25925925925925\n",
            "Accuracy Training  28:  84.25925925925925\n",
            "Accuracy Training  29:  84.25925925925925\n",
            "Accuracy Training  30:  84.25925925925925\n",
            "Accuracy Training  31:  84.25925925925925\n",
            "Accuracy Training  32:  84.25925925925925\n",
            "Accuracy Training  33:  84.25925925925925\n",
            "Accuracy Training  34:  84.25925925925925\n",
            "Accuracy Training  35:  84.25925925925925\n",
            "Accuracy Training  36:  84.25925925925925\n",
            "Accuracy Training  37:  84.25925925925925\n",
            "Accuracy Training  38:  84.25925925925925\n",
            "Accuracy Training  39:  84.25925925925925\n",
            "Accuracy Training  40:  84.25925925925925\n",
            "Accuracy Training  41:  84.25925925925925\n",
            "Accuracy Training  42:  84.25925925925925\n",
            "Accuracy Training  43:  84.25925925925925\n",
            "Accuracy Training  44:  84.25925925925925\n",
            "Accuracy Training  45:  84.25925925925925\n",
            "Accuracy Training  46:  84.25925925925925\n",
            "Accuracy Training  47:  84.25925925925925\n",
            "Accuracy Training  48:  84.25925925925925\n",
            "Accuracy Training  49:  84.25925925925925\n",
            "Accuracy Training  50:  84.25925925925925\n",
            "Accuracy Validation  :  84.51492537313433\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.975610  0.719424  0.828157    278.0\n",
            "1             0.764350  0.980620  0.859083    258.0\n",
            "avg / total   0.873922  0.845149  0.843043    536.0\n",
            "\n",
            "Iteration  3 :\n",
            "\n",
            "Accuracy Training  1:  84.25925925925925\n",
            "Accuracy Training  2:  84.25925925925925\n",
            "Accuracy Training  3:  84.25925925925925\n",
            "Accuracy Training  4:  84.25925925925925\n",
            "Accuracy Training  5:  84.25925925925925\n",
            "Accuracy Training  6:  84.25925925925925\n",
            "Accuracy Training  7:  84.25925925925925\n",
            "Accuracy Training  8:  84.25925925925925\n",
            "Accuracy Training  9:  84.25925925925925\n",
            "Accuracy Training  10:  84.25925925925925\n",
            "Accuracy Training  11:  84.25925925925925\n",
            "Accuracy Training  12:  84.25925925925925\n",
            "Accuracy Training  13:  84.25925925925925\n",
            "Accuracy Training  14:  84.25925925925925\n",
            "Accuracy Training  15:  84.25925925925925\n",
            "Accuracy Training  16:  84.25925925925925\n",
            "Accuracy Training  17:  84.25925925925925\n",
            "Accuracy Training  18:  84.25925925925925\n",
            "Accuracy Training  19:  84.25925925925925\n",
            "Accuracy Training  20:  84.25925925925925\n",
            "Accuracy Training  21:  84.25925925925925\n",
            "Accuracy Training  22:  84.25925925925925\n",
            "Accuracy Training  23:  84.25925925925925\n",
            "Accuracy Training  24:  84.25925925925925\n",
            "Accuracy Training  25:  84.25925925925925\n",
            "Accuracy Training  26:  84.25925925925925\n",
            "Accuracy Training  27:  84.25925925925925\n",
            "Accuracy Training  28:  84.25925925925925\n",
            "Accuracy Training  29:  84.25925925925925\n",
            "Accuracy Training  30:  84.25925925925925\n",
            "Accuracy Training  31:  84.25925925925925\n",
            "Accuracy Training  32:  84.25925925925925\n",
            "Accuracy Training  33:  84.25925925925925\n",
            "Accuracy Training  34:  84.25925925925925\n",
            "Accuracy Training  35:  84.25925925925925\n",
            "Accuracy Training  36:  84.25925925925925\n",
            "Accuracy Training  37:  84.25925925925925\n",
            "Accuracy Training  38:  84.25925925925925\n",
            "Accuracy Training  39:  84.25925925925925\n",
            "Accuracy Training  40:  84.25925925925925\n",
            "Accuracy Training  41:  84.25925925925925\n",
            "Accuracy Training  42:  84.25925925925925\n",
            "Accuracy Training  43:  84.25925925925925\n",
            "Accuracy Training  44:  84.25925925925925\n",
            "Accuracy Training  45:  84.25925925925925\n",
            "Accuracy Training  46:  84.25925925925925\n",
            "Accuracy Training  47:  84.25925925925925\n",
            "Accuracy Training  48:  84.25925925925925\n",
            "Accuracy Training  49:  84.25925925925925\n",
            "Accuracy Training  50:  84.25925925925925\n",
            "Accuracy Validation  :  84.51492537313433\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.975610  0.719424  0.828157    278.0\n",
            "1             0.764350  0.980620  0.859083    258.0\n",
            "avg / total   0.873922  0.845149  0.843043    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.975;0.7014388489208633;0.8158995815899581;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.7529761904761905;0.9806201550387597;0.8518...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.8681303304904052;0.8358208955223...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.975;0.7014388489208633;0.8158995815899581;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.7529761904761905;0.9806201550387597;0.8518...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.8681303304904052;0.8358208955223...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0;0.975609756097561;0.7194244604316546;0.82815...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1;0.7643504531722054;0.9806201550387597;0.8590...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>avg / total;0.8739215095402069;0.8451492537313...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ;precision;recall;f1-score;support\n",
              "0   0;0.975;0.7014388489208633;0.8158995815899581;...\n",
              "1   1;0.7529761904761905;0.9806201550387597;0.8518...\n",
              "2   avg / total;0.8681303304904052;0.8358208955223...\n",
              "3                  ;precision;recall;f1-score;support\n",
              "4   0;0.975;0.7014388489208633;0.8158995815899581;...\n",
              "5   1;0.7529761904761905;0.9806201550387597;0.8518...\n",
              "6   avg / total;0.8681303304904052;0.8358208955223...\n",
              "7                  ;precision;recall;f1-score;support\n",
              "8   0;0.975609756097561;0.7194244604316546;0.82815...\n",
              "9   1;0.7643504531722054;0.9806201550387597;0.8590...\n",
              "10  avg / total;0.8739215095402069;0.8451492537313..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwsKD8oEY1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83269761-e083-44a6-e112-86b06a306e2e"
      },
      "source": [
        "gaussian()\n",
        "show3 = pd.read_csv('GaussianReport_50_2.csv')\n",
        "show3"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  1 :\n",
            "\n",
            "Accuracy Training  1:  80.55555555555556\n",
            "Accuracy Training  2:  80.55555555555556\n",
            "Accuracy Training  3:  80.55555555555556\n",
            "Accuracy Training  4:  80.55555555555556\n",
            "Accuracy Training  5:  80.55555555555556\n",
            "Accuracy Training  6:  80.55555555555556\n",
            "Accuracy Training  7:  80.55555555555556\n",
            "Accuracy Training  8:  80.55555555555556\n",
            "Accuracy Training  9:  80.55555555555556\n",
            "Accuracy Training  10:  80.55555555555556\n",
            "Accuracy Training  11:  80.55555555555556\n",
            "Accuracy Training  12:  80.55555555555556\n",
            "Accuracy Training  13:  80.55555555555556\n",
            "Accuracy Training  14:  80.55555555555556\n",
            "Accuracy Training  15:  80.55555555555556\n",
            "Accuracy Training  16:  80.55555555555556\n",
            "Accuracy Training  17:  80.55555555555556\n",
            "Accuracy Training  18:  80.55555555555556\n",
            "Accuracy Training  19:  80.55555555555556\n",
            "Accuracy Training  20:  80.55555555555556\n",
            "Accuracy Training  21:  80.55555555555556\n",
            "Accuracy Training  22:  80.55555555555556\n",
            "Accuracy Training  23:  80.55555555555556\n",
            "Accuracy Training  24:  80.55555555555556\n",
            "Accuracy Training  25:  80.55555555555556\n",
            "Accuracy Training  26:  80.55555555555556\n",
            "Accuracy Training  27:  80.55555555555556\n",
            "Accuracy Training  28:  80.55555555555556\n",
            "Accuracy Training  29:  80.55555555555556\n",
            "Accuracy Training  30:  80.55555555555556\n",
            "Accuracy Training  31:  80.55555555555556\n",
            "Accuracy Training  32:  80.55555555555556\n",
            "Accuracy Training  33:  80.55555555555556\n",
            "Accuracy Training  34:  80.55555555555556\n",
            "Accuracy Training  35:  80.55555555555556\n",
            "Accuracy Training  36:  80.55555555555556\n",
            "Accuracy Training  37:  80.55555555555556\n",
            "Accuracy Training  38:  80.55555555555556\n",
            "Accuracy Training  39:  80.55555555555556\n",
            "Accuracy Training  40:  80.55555555555556\n",
            "Accuracy Training  41:  80.55555555555556\n",
            "Accuracy Training  42:  80.55555555555556\n",
            "Accuracy Training  43:  80.55555555555556\n",
            "Accuracy Training  44:  80.55555555555556\n",
            "Accuracy Training  45:  80.55555555555556\n",
            "Accuracy Training  46:  80.55555555555556\n",
            "Accuracy Training  47:  80.55555555555556\n",
            "Accuracy Training  48:  80.55555555555556\n",
            "Accuracy Training  49:  80.55555555555556\n",
            "Accuracy Training  50:  80.55555555555556\n",
            "Accuracy Validation  :  83.95522388059702\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.966019  0.715827  0.822314    278.0\n",
            "1             0.760606  0.972868  0.853741    258.0\n",
            "avg / total   0.867145  0.839552  0.837441    536.0\n",
            "\n",
            "Iteration  2 :\n",
            "\n",
            "Accuracy Training  1:  80.55555555555556\n",
            "Accuracy Training  2:  80.55555555555556\n",
            "Accuracy Training  3:  80.55555555555556\n",
            "Accuracy Training  4:  80.55555555555556\n",
            "Accuracy Training  5:  80.55555555555556\n",
            "Accuracy Training  6:  80.55555555555556\n",
            "Accuracy Training  7:  80.55555555555556\n",
            "Accuracy Training  8:  80.55555555555556\n",
            "Accuracy Training  9:  80.55555555555556\n",
            "Accuracy Training  10:  80.55555555555556\n",
            "Accuracy Training  11:  80.55555555555556\n",
            "Accuracy Training  12:  80.55555555555556\n",
            "Accuracy Training  13:  80.55555555555556\n",
            "Accuracy Training  14:  80.55555555555556\n",
            "Accuracy Training  15:  80.55555555555556\n",
            "Accuracy Training  16:  80.55555555555556\n",
            "Accuracy Training  17:  80.55555555555556\n",
            "Accuracy Training  18:  80.55555555555556\n",
            "Accuracy Training  19:  80.55555555555556\n",
            "Accuracy Training  20:  80.55555555555556\n",
            "Accuracy Training  21:  80.55555555555556\n",
            "Accuracy Training  22:  80.55555555555556\n",
            "Accuracy Training  23:  80.55555555555556\n",
            "Accuracy Training  24:  80.55555555555556\n",
            "Accuracy Training  25:  80.55555555555556\n",
            "Accuracy Training  26:  80.55555555555556\n",
            "Accuracy Training  27:  80.55555555555556\n",
            "Accuracy Training  28:  80.55555555555556\n",
            "Accuracy Training  29:  80.55555555555556\n",
            "Accuracy Training  30:  80.55555555555556\n",
            "Accuracy Training  31:  80.55555555555556\n",
            "Accuracy Training  32:  80.55555555555556\n",
            "Accuracy Training  33:  80.55555555555556\n",
            "Accuracy Training  34:  80.55555555555556\n",
            "Accuracy Training  35:  80.55555555555556\n",
            "Accuracy Training  36:  80.55555555555556\n",
            "Accuracy Training  37:  80.55555555555556\n",
            "Accuracy Training  38:  80.55555555555556\n",
            "Accuracy Training  39:  80.55555555555556\n",
            "Accuracy Training  40:  80.55555555555556\n",
            "Accuracy Training  41:  80.55555555555556\n",
            "Accuracy Training  42:  80.55555555555556\n",
            "Accuracy Training  43:  80.55555555555556\n",
            "Accuracy Training  44:  80.55555555555556\n",
            "Accuracy Training  45:  80.55555555555556\n",
            "Accuracy Training  46:  80.55555555555556\n",
            "Accuracy Training  47:  80.55555555555556\n",
            "Accuracy Training  48:  80.55555555555556\n",
            "Accuracy Training  49:  80.55555555555556\n",
            "Accuracy Training  50:  80.55555555555556\n",
            "Accuracy Validation  :  83.95522388059702\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.966019  0.715827  0.822314    278.0\n",
            "1             0.760606  0.972868  0.853741    258.0\n",
            "avg / total   0.867145  0.839552  0.837441    536.0\n",
            "\n",
            "Iteration  3 :\n",
            "\n",
            "Accuracy Training  1:  80.55555555555556\n",
            "Accuracy Training  2:  80.55555555555556\n",
            "Accuracy Training  3:  80.55555555555556\n",
            "Accuracy Training  4:  80.55555555555556\n",
            "Accuracy Training  5:  80.55555555555556\n",
            "Accuracy Training  6:  80.55555555555556\n",
            "Accuracy Training  7:  80.55555555555556\n",
            "Accuracy Training  8:  80.55555555555556\n",
            "Accuracy Training  9:  80.55555555555556\n",
            "Accuracy Training  10:  80.55555555555556\n",
            "Accuracy Training  11:  80.55555555555556\n",
            "Accuracy Training  12:  80.55555555555556\n",
            "Accuracy Training  13:  80.55555555555556\n",
            "Accuracy Training  14:  80.55555555555556\n",
            "Accuracy Training  15:  80.55555555555556\n",
            "Accuracy Training  16:  80.55555555555556\n",
            "Accuracy Training  17:  80.55555555555556\n",
            "Accuracy Training  18:  80.55555555555556\n",
            "Accuracy Training  19:  80.55555555555556\n",
            "Accuracy Training  20:  80.55555555555556\n",
            "Accuracy Training  21:  80.55555555555556\n",
            "Accuracy Training  22:  80.55555555555556\n",
            "Accuracy Training  23:  80.55555555555556\n",
            "Accuracy Training  24:  80.55555555555556\n",
            "Accuracy Training  25:  80.55555555555556\n",
            "Accuracy Training  26:  80.55555555555556\n",
            "Accuracy Training  27:  80.55555555555556\n",
            "Accuracy Training  28:  80.55555555555556\n",
            "Accuracy Training  29:  80.55555555555556\n",
            "Accuracy Training  30:  80.55555555555556\n",
            "Accuracy Training  31:  80.55555555555556\n",
            "Accuracy Training  32:  80.55555555555556\n",
            "Accuracy Training  33:  80.55555555555556\n",
            "Accuracy Training  34:  80.55555555555556\n",
            "Accuracy Training  35:  80.55555555555556\n",
            "Accuracy Training  36:  80.55555555555556\n",
            "Accuracy Training  37:  80.55555555555556\n",
            "Accuracy Training  38:  80.55555555555556\n",
            "Accuracy Training  39:  80.55555555555556\n",
            "Accuracy Training  40:  80.55555555555556\n",
            "Accuracy Training  41:  80.55555555555556\n",
            "Accuracy Training  42:  80.55555555555556\n",
            "Accuracy Training  43:  80.55555555555556\n",
            "Accuracy Training  44:  80.55555555555556\n",
            "Accuracy Training  45:  80.55555555555556\n",
            "Accuracy Training  46:  80.55555555555556\n",
            "Accuracy Training  47:  80.55555555555556\n",
            "Accuracy Training  48:  80.55555555555556\n",
            "Accuracy Training  49:  80.55555555555556\n",
            "Accuracy Training  50:  80.55555555555556\n",
            "Accuracy Validation  :  83.95522388059702\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.966019  0.715827  0.822314    278.0\n",
            "1             0.760606  0.972868  0.853741    258.0\n",
            "avg / total   0.867145  0.839552  0.837441    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.9655172413793104;0.7050359712230215;0.8149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.7537537537537538;0.9728682170542635;0.8494...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.8635863089028298;0.8339552238805...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.9655172413793104;0.7050359712230215;0.8149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.7537537537537538;0.9728682170542635;0.8494...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.8635863089028298;0.8339552238805...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0;0.9660194174757282;0.7158273381294964;0.8223...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1;0.7606060606060606;0.9728682170542635;0.8537...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>avg / total;0.8671450777884628;0.8395522388059...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ;precision;recall;f1-score;support\n",
              "0   0;0.9655172413793104;0.7050359712230215;0.8149...\n",
              "1   1;0.7537537537537538;0.9728682170542635;0.8494...\n",
              "2   avg / total;0.8635863089028298;0.8339552238805...\n",
              "3                  ;precision;recall;f1-score;support\n",
              "4   0;0.9655172413793104;0.7050359712230215;0.8149...\n",
              "5   1;0.7537537537537538;0.9728682170542635;0.8494...\n",
              "6   avg / total;0.8635863089028298;0.8339552238805...\n",
              "7                  ;precision;recall;f1-score;support\n",
              "8   0;0.9660194174757282;0.7158273381294964;0.8223...\n",
              "9   1;0.7606060606060606;0.9728682170542635;0.8537...\n",
              "10  avg / total;0.8671450777884628;0.8395522388059..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3xKgtY8EYZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1eb3d083-d33c-4cdc-ac17-be02a5120b1b"
      },
      "source": [
        "sigmoid()\n",
        "show4 = pd.read_csv('SigmoidReport_50_2.csv')\n",
        "show4"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  1 :\n",
            "\n",
            "Accuracy Training  1:  51.85185185185185\n",
            "Accuracy Training  2:  51.85185185185185\n",
            "Accuracy Training  3:  51.85185185185185\n",
            "Accuracy Training  4:  51.85185185185185\n",
            "Accuracy Training  5:  51.85185185185185\n",
            "Accuracy Training  6:  51.85185185185185\n",
            "Accuracy Training  7:  51.85185185185185\n",
            "Accuracy Training  8:  51.85185185185185\n",
            "Accuracy Training  9:  51.85185185185185\n",
            "Accuracy Training  10:  51.85185185185185\n",
            "Accuracy Training  11:  51.85185185185185\n",
            "Accuracy Training  12:  51.85185185185185\n",
            "Accuracy Training  13:  51.85185185185185\n",
            "Accuracy Training  14:  51.85185185185185\n",
            "Accuracy Training  15:  51.85185185185185\n",
            "Accuracy Training  16:  51.85185185185185\n",
            "Accuracy Training  17:  51.85185185185185\n",
            "Accuracy Training  18:  51.85185185185185\n",
            "Accuracy Training  19:  51.85185185185185\n",
            "Accuracy Training  20:  51.85185185185185\n",
            "Accuracy Training  21:  51.85185185185185\n",
            "Accuracy Training  22:  51.85185185185185\n",
            "Accuracy Training  23:  51.85185185185185\n",
            "Accuracy Training  24:  51.85185185185185\n",
            "Accuracy Training  25:  51.85185185185185\n",
            "Accuracy Training  26:  51.85185185185185\n",
            "Accuracy Training  27:  51.85185185185185\n",
            "Accuracy Training  28:  51.85185185185185\n",
            "Accuracy Training  29:  51.85185185185185\n",
            "Accuracy Training  30:  51.85185185185185\n",
            "Accuracy Training  31:  51.85185185185185\n",
            "Accuracy Training  32:  51.85185185185185\n",
            "Accuracy Training  33:  51.85185185185185\n",
            "Accuracy Training  34:  51.85185185185185\n",
            "Accuracy Training  35:  51.85185185185185\n",
            "Accuracy Training  36:  51.85185185185185\n",
            "Accuracy Training  37:  51.85185185185185\n",
            "Accuracy Training  38:  51.85185185185185\n",
            "Accuracy Training  39:  51.85185185185185\n",
            "Accuracy Training  40:  51.85185185185185\n",
            "Accuracy Training  41:  51.85185185185185\n",
            "Accuracy Training  42:  51.85185185185185\n",
            "Accuracy Training  43:  51.85185185185185\n",
            "Accuracy Training  44:  51.85185185185185\n",
            "Accuracy Training  45:  51.85185185185185\n",
            "Accuracy Training  46:  51.85185185185185\n",
            "Accuracy Training  47:  51.85185185185185\n",
            "Accuracy Training  48:  51.85185185185185\n",
            "Accuracy Training  49:  51.85185185185185\n",
            "Accuracy Training  50:  51.85185185185185\n",
            "Accuracy Validation  :  51.865671641791046\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.518657  1.000000  0.683047    278.0\n",
            "1             0.000000  0.000000  0.000000    258.0\n",
            "avg / total   0.269005  0.518657  0.354267    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  2 :\n",
            "\n",
            "Accuracy Training  1:  51.85185185185185\n",
            "Accuracy Training  2:  51.85185185185185\n",
            "Accuracy Training  3:  51.85185185185185\n",
            "Accuracy Training  4:  51.85185185185185\n",
            "Accuracy Training  5:  51.85185185185185\n",
            "Accuracy Training  6:  51.85185185185185\n",
            "Accuracy Training  7:  51.85185185185185\n",
            "Accuracy Training  8:  51.85185185185185\n",
            "Accuracy Training  9:  51.85185185185185\n",
            "Accuracy Training  10:  51.85185185185185\n",
            "Accuracy Training  11:  51.85185185185185\n",
            "Accuracy Training  12:  51.85185185185185\n",
            "Accuracy Training  13:  51.85185185185185\n",
            "Accuracy Training  14:  51.85185185185185\n",
            "Accuracy Training  15:  51.85185185185185\n",
            "Accuracy Training  16:  51.85185185185185\n",
            "Accuracy Training  17:  51.85185185185185\n",
            "Accuracy Training  18:  51.85185185185185\n",
            "Accuracy Training  19:  51.85185185185185\n",
            "Accuracy Training  20:  51.85185185185185\n",
            "Accuracy Training  21:  51.85185185185185\n",
            "Accuracy Training  22:  51.85185185185185\n",
            "Accuracy Training  23:  51.85185185185185\n",
            "Accuracy Training  24:  51.85185185185185\n",
            "Accuracy Training  25:  51.85185185185185\n",
            "Accuracy Training  26:  51.85185185185185\n",
            "Accuracy Training  27:  51.85185185185185\n",
            "Accuracy Training  28:  51.85185185185185\n",
            "Accuracy Training  29:  51.85185185185185\n",
            "Accuracy Training  30:  51.85185185185185\n",
            "Accuracy Training  31:  51.85185185185185\n",
            "Accuracy Training  32:  51.85185185185185\n",
            "Accuracy Training  33:  51.85185185185185\n",
            "Accuracy Training  34:  51.85185185185185\n",
            "Accuracy Training  35:  51.85185185185185\n",
            "Accuracy Training  36:  51.85185185185185\n",
            "Accuracy Training  37:  51.85185185185185\n",
            "Accuracy Training  38:  51.85185185185185\n",
            "Accuracy Training  39:  51.85185185185185\n",
            "Accuracy Training  40:  51.85185185185185\n",
            "Accuracy Training  41:  51.85185185185185\n",
            "Accuracy Training  42:  51.85185185185185\n",
            "Accuracy Training  43:  51.85185185185185\n",
            "Accuracy Training  44:  51.85185185185185\n",
            "Accuracy Training  45:  51.85185185185185\n",
            "Accuracy Training  46:  51.85185185185185\n",
            "Accuracy Training  47:  51.85185185185185\n",
            "Accuracy Training  48:  51.85185185185185\n",
            "Accuracy Training  49:  51.85185185185185\n",
            "Accuracy Training  50:  51.85185185185185\n",
            "Accuracy Validation  :  51.865671641791046\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.518657  1.000000  0.683047    278.0\n",
            "1             0.000000  0.000000  0.000000    258.0\n",
            "avg / total   0.269005  0.518657  0.354267    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration  3 :\n",
            "\n",
            "Accuracy Training  1:  51.85185185185185\n",
            "Accuracy Training  2:  51.85185185185185\n",
            "Accuracy Training  3:  51.85185185185185\n",
            "Accuracy Training  4:  51.85185185185185\n",
            "Accuracy Training  5:  51.85185185185185\n",
            "Accuracy Training  6:  51.85185185185185\n",
            "Accuracy Training  7:  51.85185185185185\n",
            "Accuracy Training  8:  51.85185185185185\n",
            "Accuracy Training  9:  51.85185185185185\n",
            "Accuracy Training  10:  51.85185185185185\n",
            "Accuracy Training  11:  51.85185185185185\n",
            "Accuracy Training  12:  51.85185185185185\n",
            "Accuracy Training  13:  51.85185185185185\n",
            "Accuracy Training  14:  51.85185185185185\n",
            "Accuracy Training  15:  51.85185185185185\n",
            "Accuracy Training  16:  51.85185185185185\n",
            "Accuracy Training  17:  51.85185185185185\n",
            "Accuracy Training  18:  51.85185185185185\n",
            "Accuracy Training  19:  51.85185185185185\n",
            "Accuracy Training  20:  51.85185185185185\n",
            "Accuracy Training  21:  51.85185185185185\n",
            "Accuracy Training  22:  51.85185185185185\n",
            "Accuracy Training  23:  51.85185185185185\n",
            "Accuracy Training  24:  51.85185185185185\n",
            "Accuracy Training  25:  51.85185185185185\n",
            "Accuracy Training  26:  51.85185185185185\n",
            "Accuracy Training  27:  51.85185185185185\n",
            "Accuracy Training  28:  51.85185185185185\n",
            "Accuracy Training  29:  51.85185185185185\n",
            "Accuracy Training  30:  51.85185185185185\n",
            "Accuracy Training  31:  51.85185185185185\n",
            "Accuracy Training  32:  51.85185185185185\n",
            "Accuracy Training  33:  51.85185185185185\n",
            "Accuracy Training  34:  51.85185185185185\n",
            "Accuracy Training  35:  51.85185185185185\n",
            "Accuracy Training  36:  51.85185185185185\n",
            "Accuracy Training  37:  51.85185185185185\n",
            "Accuracy Training  38:  51.85185185185185\n",
            "Accuracy Training  39:  51.85185185185185\n",
            "Accuracy Training  40:  51.85185185185185\n",
            "Accuracy Training  41:  51.85185185185185\n",
            "Accuracy Training  42:  51.85185185185185\n",
            "Accuracy Training  43:  51.85185185185185\n",
            "Accuracy Training  44:  51.85185185185185\n",
            "Accuracy Training  45:  51.85185185185185\n",
            "Accuracy Training  46:  51.85185185185185\n",
            "Accuracy Training  47:  51.85185185185185\n",
            "Accuracy Training  48:  51.85185185185185\n",
            "Accuracy Training  49:  51.85185185185185\n",
            "Accuracy Training  50:  51.85185185185185\n",
            "Accuracy Validation  :  51.865671641791046\n",
            "Class Report         : \n",
            "              precision    recall  f1-score  support\n",
            "0             0.518657  1.000000  0.683047    278.0\n",
            "1             0.000000  0.000000  0.000000    258.0\n",
            "avg / total   0.269005  0.518657  0.354267    536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.5186567164179104;1.0;0.6830466830466831;278.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.0;0.0;0.0;258.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.2690047894854088;0.5186567164179...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.5186567164179104;1.0;0.6830466830466831;278.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.0;0.0;0.0;258.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.2690047894854088;0.5186567164179...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0;0.5186567164179104;1.0;0.6830466830466831;278.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1;0.0;0.0;0.0;258.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>avg / total;0.2690047894854088;0.5186567164179...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ;precision;recall;f1-score;support\n",
              "0   0;0.5186567164179104;1.0;0.6830466830466831;278.0\n",
              "1                                 1;0.0;0.0;0.0;258.0\n",
              "2   avg / total;0.2690047894854088;0.5186567164179...\n",
              "3                  ;precision;recall;f1-score;support\n",
              "4   0;0.5186567164179104;1.0;0.6830466830466831;278.0\n",
              "5                                 1;0.0;0.0;0.0;258.0\n",
              "6   avg / total;0.2690047894854088;0.5186567164179...\n",
              "7                  ;precision;recall;f1-score;support\n",
              "8   0;0.5186567164179104;1.0;0.6830466830466831;278.0\n",
              "9                                 1;0.0;0.0;0.0;258.0\n",
              "10  avg / total;0.2690047894854088;0.5186567164179..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCXWxmN8F2nW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "6f195616-60d7-4d37-b4d1-7d69012d486b"
      },
      "source": [
        "show5 = pd.read_csv('GaussianReport_50_2.csv')\n",
        "show5"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;precision;recall;f1-score;support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;0.9655172413793104;0.7050359712230215;0.8149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;0.7537537537537538;0.9728682170542635;0.8494...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg / total;0.8635863089028298;0.8339552238805...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0;0.9655172413793104;0.7050359712230215;0.8149...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1;0.7537537537537538;0.9728682170542635;0.8494...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg / total;0.8635863089028298;0.8339552238805...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>;precision;recall;f1-score;support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0;0.9660194174757282;0.7158273381294964;0.8223...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1;0.7606060606060606;0.9728682170542635;0.8537...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>avg / total;0.8671450777884628;0.8395522388059...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ;precision;recall;f1-score;support\n",
              "0   0;0.9655172413793104;0.7050359712230215;0.8149...\n",
              "1   1;0.7537537537537538;0.9728682170542635;0.8494...\n",
              "2   avg / total;0.8635863089028298;0.8339552238805...\n",
              "3                  ;precision;recall;f1-score;support\n",
              "4   0;0.9655172413793104;0.7050359712230215;0.8149...\n",
              "5   1;0.7537537537537538;0.9728682170542635;0.8494...\n",
              "6   avg / total;0.8635863089028298;0.8339552238805...\n",
              "7                  ;precision;recall;f1-score;support\n",
              "8   0;0.9660194174757282;0.7158273381294964;0.8223...\n",
              "9   1;0.7606060606060606;0.9728682170542635;0.8537...\n",
              "10  avg / total;0.8671450777884628;0.8395522388059..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}